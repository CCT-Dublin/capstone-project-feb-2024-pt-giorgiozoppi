{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>TrackML/HotelRank</b>: Elevating Revenue Performance Through Machine Learning and Deep Learning Techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenue management is a very important to make profits in the hotel industry, three main factors play an important role to get it right:  \n",
    "    <ol>\n",
    "    <li>Hotel room demand over time (demand forecast).</li>\n",
    "    <li>Prediction of booking cancellations.</li>\n",
    "    <li>Online hotel reputation.</li>\n",
    "    </ol>\n",
    "In this project we take in account each one thru a linear combination of different scores that represent each item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>DemandScore</b>: Demand Forecast over 12 months booking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective to section to concentrate ourselves to demand forecast with just Blastness dataset and nothing more:\n",
    "- We have to clean the data provided and see patterns.\n",
    "- Detect outliers in the demand\n",
    "- Compare SARIMAX and prophet neural network to see which fits better for the demandscore.\n",
    "- Create the demand score for each hotel using booking forecast in next temporal year frame.\n",
    "- We leave to future work any crossdata about the demand related to weather and external events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bamboolib in /home/jozoppi/anaconda3/lib/python3.12/site-packages (1.30.19)\n",
      "Requirement already satisfied: attrs>=20.3.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (23.1.0)\n",
      "Requirement already satisfied: cryptography>=2.6.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (42.0.5)\n",
      "Requirement already satisfied: ipywidgets<8.0.0,>=7.6.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (7.8.1)\n",
      "Requirement already satisfied: jedi<1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (0.18.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (1.5.3)\n",
      "Requirement already satisfied: packaging>=19.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (23.2)\n",
      "Requirement already satisfied: plotly<6.0.0,>=4.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (5.22.0)\n",
      "Requirement already satisfied: ppscore<2.0.0,>=1.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (1.3.0)\n",
      "Requirement already satisfied: psutil<6,>=5.4.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (5.9.0)\n",
      "Requirement already satisfied: pygments in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (2.15.1)\n",
      "Requirement already satisfied: ipyslickgrid==0.0.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (0.0.3)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (1.4.2)\n",
      "Requirement already satisfied: statsmodels<1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (0.14.2)\n",
      "Requirement already satisfied: toml>=0.10.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (0.10.2)\n",
      "Requirement already satisfied: xlrd>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (2.0.1)\n",
      "Requirement already satisfied: notebook>=4.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipyslickgrid==0.0.3->bamboolib) (7.0.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cryptography>=2.6.1->bamboolib) (1.16.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (3.6.6)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (8.25.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (1.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jedi<1.0.0->bamboolib) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (1.26.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from plotly<6.0.0,>=4.9.0->bamboolib) (8.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from statsmodels<1.0.0->bamboolib) (0.5.6)\n",
      "Requirement already satisfied: pycparser in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.6.1->bamboolib) (2.21)\n",
      "Requirement already satisfied: decorator in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (3.0.43)\n",
      "Requirement already satisfied: stack-data in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (4.8.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (6.4.1)\n",
      "Requirement already satisfied: six in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels<1.0.0->bamboolib) (1.16.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (7.10.0)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (5.9.2)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.14.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.4)\n",
      "Requirement already satisfied: ipykernel in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (6.28.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.32.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.5)\n",
      "Requirement already satisfied: executing in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (3.10.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2024.8.30)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.6.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.6.0)\n",
      "Requirement already satisfied: webencodings in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.1)\n",
      "Requirement already satisfied: uri-template in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (24.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.5)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.2.3)\n",
      "Requirement already satisfied: pandas in /home/jozoppi/anaconda3/lib/python3.12/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/jozoppi/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: seaborn in /home/jozoppi/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplot in /home/jozoppi/anaconda3/lib/python3.12/site-packages (0.1.9)\n",
      "Requirement already satisfied: scikit-learn in /home/jozoppi/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyarrow in /home/jozoppi/anaconda3/lib/python3.12/site-packages (17.0.0)\n",
      "Requirement already satisfied: prophet in /home/jozoppi/anaconda3/lib/python3.12/site-packages (1.1.6)\n",
      "Requirement already satisfied: statsmodels in /home/jozoppi/anaconda3/lib/python3.12/site-packages (0.14.2)\n",
      "Requirement already satisfied: pycaret in /home/jozoppi/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
      "Requirement already satisfied: datasets in /home/jozoppi/anaconda3/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from seaborn) (3.7.5)\n",
      "Requirement already satisfied: pyloco>=0.0.134 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplot) (0.0.139)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prophet) (1.2.4)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prophet) (0.58)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prophet) (4.66.4)\n",
      "Requirement already satisfied: importlib-resources in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prophet) (6.4.5)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (8.25.0)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (7.8.1)\n",
      "Requirement already satisfied: jinja2>=3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (3.1.4)\n",
      "Requirement already satisfied: pyod>=1.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.0.2)\n",
      "Requirement already satisfied: imbalanced-learn>=0.12.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.12.3)\n",
      "Requirement already satisfied: category-encoders>=2.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.6.4)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (4.5.0)\n",
      "Requirement already satisfied: numba>=0.55.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.59.1)\n",
      "Requirement already satisfied: requests>=2.27.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.32.2)\n",
      "Requirement already satisfied: psutil>=5.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (5.9.0)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (7.0.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (5.9.2)\n",
      "Requirement already satisfied: cloudpickle in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.2.1)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.1.0)\n",
      "Requirement already satisfied: xxhash in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (3.5.0)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.3.7)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (1.5)\n",
      "Requirement already satisfied: plotly>=5.14.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (5.22.0)\n",
      "Requirement already satisfied: kaleido>=0.2.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.2.1)\n",
      "Requirement already satisfied: schemdraw==0.15 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.15)\n",
      "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.10.0)\n",
      "Requirement already satisfied: sktime==0.26.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.26.0)\n",
      "Requirement already satisfied: tbats>=1.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (1.1.3)\n",
      "Requirement already satisfied: pmdarima>=2.0.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.0.4)\n",
      "Requirement already satisfied: wurlitzer in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (3.0.2)\n",
      "Requirement already satisfied: scikit-base<0.8.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from sktime==0.26.0->pycaret) (0.7.8)\n",
      "Requirement already satisfied: filelock in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: multiprocess in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (0.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.22.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from importlib-metadata>=4.12.0->pycaret) (3.17.0)\n",
      "Requirement already satisfied: decorator in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (4.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets>=7.6.5->pycaret) (0.2.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets>=7.6.5->pycaret) (3.6.6)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets>=7.6.5->pycaret) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: fastjsonschema in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbformat>=4.2.0->pycaret) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbformat>=4.2.0->pycaret) (4.19.2)\n",
      "Requirement already satisfied: jupyter-core in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from numba>=0.55.0->pycaret) (0.42.0)\n",
      "Requirement already satisfied: six in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from plotly>=5.14.0->pycaret) (8.2.2)\n",
      "Requirement already satisfied: dash>=2.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from plotly-resampler>=0.8.3.1->pycaret) (2.18.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.10.7)\n",
      "Requirement already satisfied: tsdownsample>=0.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.3)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pmdarima>=2.0.4->pycaret) (3.0.11)\n",
      "Requirement already satisfied: urllib3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pmdarima>=2.0.4->pycaret) (2.2.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pmdarima>=2.0.4->pycaret) (69.5.1)\n",
      "Requirement already satisfied: ushlex in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pyloco>=0.0.134->matplot) (0.99.1)\n",
      "Requirement already satisfied: websocket-client in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pyloco>=0.0.134->matplot) (1.8.0)\n",
      "Requirement already satisfied: twine in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pyloco>=0.0.134->matplot) (5.1.1)\n",
      "Requirement already satisfied: typing in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pyloco>=0.0.134->matplot) (3.7.4.3)\n",
      "Requirement already satisfied: SimpleWebSocketServer in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pyloco>=0.0.134->matplot) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.27.1->pycaret) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.27.1->pycaret) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.27.1->pycaret) (2024.8.30)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (5.0.0)\n",
      "Requirement already satisfied: retrying in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.10.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (7.0.8)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-core->nbformat>=4.2.0->pycaret) (3.10.0)\n",
      "Requirement already satisfied: executing in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=5.5.0->pycaret) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=5.5.0->pycaret) (0.2.2)\n",
      "Requirement already satisfied: pkginfo>=1.8.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (1.10.0)\n",
      "Requirement already satisfied: readme-renderer>=35.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (44.0)\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (1.0.0)\n",
      "Requirement already satisfied: keyring>=15.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (24.3.1)\n",
      "Requirement already satisfied: rfc3986>=1.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (2.0.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (13.3.5)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.2)\n",
      "Requirement already satisfied: jaraco.classes in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (3.2.1)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (3.3.1)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (0.7.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (6.4.1)\n",
      "Requirement already satisfied: nh3>=0.2.14 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot) (0.2.18)\n",
      "Requirement already satisfied: docutils>=0.21.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot) (0.21.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (2.2.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (8.6.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (7.10.0)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.14.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.17.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.0.4)\n",
      "Requirement already satisfied: ipykernel in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (6.28.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.9.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (0.1.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (42.0.5)\n",
      "Requirement already satisfied: more-itertools in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jaraco.classes->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (10.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (1.16.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.6.7)\n",
      "Requirement already satisfied: webencodings in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (2.21)\n",
      "Requirement already satisfied: fqdn in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.1)\n",
      "Requirement already satisfied: uri-template in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (24.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.5)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.2.3)\n",
      "Trying to install bamboolib nbextension...\n",
      "Could not install bamboolib Jupyter Notebook extension because Jupyter Notebook is not available\n"
     ]
    }
   ],
   "source": [
    "!pip install bamboolib\n",
    "!pip install pandas numpy seaborn matplot scikit-learn pyarrow prophet statsmodels pycaret datasets \n",
    "!python -m bamboolib install_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first action we load the csv provided by Blastness and we create a dataset with columns names in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26651/2239760973.py:18: DtypeWarning: Columns (23,53,62,68,70,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "/tmp/ipykernel_26651/2239760973.py:18: DtypeWarning: Columns (23,52,55,58,59,60,81,89,90,91) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "/tmp/ipykernel_26651/2239760973.py:18: DtypeWarning: Columns (23,49,55,59,81,87,90) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "/tmp/ipykernel_26651/2239760973.py:18: DtypeWarning: Columns (23,52,53,55,58,59,60,62,68,70,81,89,90,91) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19887PMCMTT6</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>23/10/2021</td>\n",
       "      <td>30/10/2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>31/05/2021</td>\n",
       "      <td>Website</td>\n",
       "      <td>31/05/2021 17:37:31</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19887FBFWGZ7</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>31/07/2021</td>\n",
       "      <td>06/08/2021</td>\n",
       "      <td>6</td>\n",
       "      <td>2894,25</td>\n",
       "      <td>08/07/2021</td>\n",
       "      <td>Website</td>\n",
       "      <td>08/07/2021 22:23:51</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19887JIZNTR8</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>23/10/2021</td>\n",
       "      <td>26/10/2021</td>\n",
       "      <td>3</td>\n",
       "      <td>2142,00</td>\n",
       "      <td>04/10/2021</td>\n",
       "      <td>Website</td>\n",
       "      <td>04/10/2021 21:24:49</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19887CNIHY10</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>23/11/2022</td>\n",
       "      <td>28/11/2022</td>\n",
       "      <td>5</td>\n",
       "      <td>3696,00</td>\n",
       "      <td>01/06/2022</td>\n",
       "      <td>Website</td>\n",
       "      <td>01/06/2022 10:46:15</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19887GOAMJ11</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>11/10/2022</td>\n",
       "      <td>15/10/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>4488,00</td>\n",
       "      <td>26/06/2022</td>\n",
       "      <td>Website</td>\n",
       "      <td>26/06/2022 04:14:05</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Code      Status BookingChannel     Arrival   Departure  Nights  \\\n",
       "0  19887PMCMTT6  Cancellata           Sito  23/10/2021  30/10/2021       0   \n",
       "1  19887FBFWGZ7  Confermata           Sito  31/07/2021  06/08/2021       6   \n",
       "2  19887JIZNTR8  Confermata           Sito  23/10/2021  26/10/2021       3   \n",
       "3  19887CNIHY10  Confermata           Sito  23/11/2022  28/11/2022       5   \n",
       "4  19887GOAMJ11  Confermata           Sito  11/10/2022  15/10/2022       4   \n",
       "\n",
       "     Total PurchaseDate BookingDevice         LastModified HotelId  \n",
       "0     0,00   31/05/2021       Website  31/05/2021 17:37:31     010  \n",
       "1  2894,25   08/07/2021       Website  08/07/2021 22:23:51     010  \n",
       "2  2142,00   04/10/2021       Website  04/10/2021 21:24:49     010  \n",
       "3  3696,00   01/06/2022       Website  01/06/2022 10:46:15     010  \n",
       "4  4488,00   26/06/2022       Website  26/06/2022 04:14:05     010  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "filelist = glob.glob('./hoteldataset/*.csv')\n",
    "hotelsbookings = []\n",
    "column_mapping = {\n",
    "    'Codice': 'Code',\n",
    "    'Status': 'Status',\n",
    "    'Canale': 'BookingChannel',\n",
    "    'Arrivo': 'Arrival',\n",
    "    'Partenza': 'Departure',\n",
    "    'Notti': 'Nights',\n",
    "    'Totale': 'Total',\n",
    "    'Data acquisto': 'PurchaseDate',\n",
    "    'Dispositivo': 'BookingDevice',\n",
    "    'Data Ultima Modifica/Cancellazione': 'LastModified'\n",
    "}\n",
    "for idx,f in enumerate(filelist):\n",
    "    df = pd.read_csv(f)\n",
    "    select_columns = list(column_mapping.keys())\n",
    "    current_df = df[select_columns]\n",
    "    remap = current_df.rename(columns=column_mapping)\n",
    "    hotel_id = \"\"\n",
    "    if idx < 9:\n",
    "        hotel_id=f'00{idx+1}'\n",
    "    else:\n",
    "        hotel_id=f'0{idx+1}'\n",
    "\n",
    "    remap['HotelId'] = hotel_id\n",
    "    hotelsbookings.append(remap)\n",
    "hotelsbookings[9].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge all hotels in a single dataframe and save to disk. We note that we need to divide cancelled and confirmed booking. Later since we want do forecast on the confirmed.\n",
    "- Also we need to categorize the origin\n",
    "- remove the booking device.\n",
    "\n",
    "First we merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "                         Code      Status BookingChannel     Arrival  \\\n",
      "0       1400576136/1204413850  Cancellata    Booking.com  22/07/2017   \n",
      "1       1240874198/1204820657  Cancellata    Booking.com  15/07/2017   \n",
      "2       1656344835/1204828455  Cancellata    Booking.com  22/07/2017   \n",
      "3       1656344835/1204828455  Cancellata    Booking.com  22/07/2017   \n",
      "4       1656344835/1204828455  Cancellata    Booking.com  22/07/2017   \n",
      "...                       ...         ...            ...         ...   \n",
      "151852           19887FIHJR22  Confermata           Sito  19/10/2023   \n",
      "151853           19887DOSJP23  Confermata           Sito  10/06/2023   \n",
      "151854           19887KTDJJ24  Confermata           Sito  18/07/2023   \n",
      "151855           19887LNQHJ25  Confermata           Sito  24/04/2023   \n",
      "151856           19887IENNC26  Confermata           Sito  18/09/2023   \n",
      "\n",
      "         Departure  Nights    Total PurchaseDate BookingDevice  \\\n",
      "0       29/07/2017       0     0,00   01/01/2017           NaN   \n",
      "1       02/08/2017       0     0,00   01/01/2017           NaN   \n",
      "2       09/08/2017       0     0,00   01/01/2017           NaN   \n",
      "3       09/08/2017       0     0,00   01/01/2017           NaN   \n",
      "4       09/08/2017       0     0,00   01/01/2017           NaN   \n",
      "...            ...     ...      ...          ...           ...   \n",
      "151852  22/10/2023       3  3080,00   11/03/2023       Website   \n",
      "151853  12/06/2023       2  2112,00   17/03/2023       Website   \n",
      "151854  20/07/2023       2  2112,00   02/04/2023        Mobile   \n",
      "151855  27/04/2023       3  2640,00   08/04/2023       Website   \n",
      "151856  21/09/2023       3  3168,00   03/06/2023       Website   \n",
      "\n",
      "               LastModified HotelId  \n",
      "0       01/01/2017 15:27:39     001  \n",
      "1       01/01/2017 23:13:49     001  \n",
      "2       11/01/2017 21:59:16     001  \n",
      "3       10/01/2017 22:10:56     001  \n",
      "4       11/01/2017 21:59:16     001  \n",
      "...                     ...     ...  \n",
      "151852  11/03/2023 10:15:06     010  \n",
      "151853  17/03/2023 17:33:23     010  \n",
      "151854  02/04/2023 09:55:59     010  \n",
      "151855  08/04/2023 20:06:59     010  \n",
      "151856  03/06/2023 12:55:03     010  \n",
      "\n",
      "[151857 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge DataFrames\n",
    "merged_df = pd.concat(hotelsbookings, ignore_index=True)\n",
    "# Display the merged DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've seen a lot of not known or bad data. Just clean it. We want order by date, in descending mode and take only the last 2 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400576136/1204413850</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>22/07/2017</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2017 15:27:39</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240874198/1204820657</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>15/07/2017</td>\n",
       "      <td>02/08/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2017 23:13:49</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656344835/1204828455</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>22/07/2017</td>\n",
       "      <td>09/08/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/01/2017 21:59:16</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1656344835/1204828455</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>22/07/2017</td>\n",
       "      <td>09/08/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/01/2017 22:10:56</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1656344835/1204828455</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>22/07/2017</td>\n",
       "      <td>09/08/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/01/2017 21:59:16</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Code      Status BookingChannel     Arrival   Departure  \\\n",
       "0  1400576136/1204413850  Cancellata    Booking.com  22/07/2017  29/07/2017   \n",
       "1  1240874198/1204820657  Cancellata    Booking.com  15/07/2017  02/08/2017   \n",
       "2  1656344835/1204828455  Cancellata    Booking.com  22/07/2017  09/08/2017   \n",
       "3  1656344835/1204828455  Cancellata    Booking.com  22/07/2017  09/08/2017   \n",
       "4  1656344835/1204828455  Cancellata    Booking.com  22/07/2017  09/08/2017   \n",
       "\n",
       "   Nights Total PurchaseDate BookingDevice         LastModified HotelId  \n",
       "0       0  0,00   01/01/2017           NaN  01/01/2017 15:27:39     001  \n",
       "1       0  0,00   01/01/2017           NaN  01/01/2017 23:13:49     001  \n",
       "2       0  0,00   01/01/2017           NaN  11/01/2017 21:59:16     001  \n",
       "3       0  0,00   01/01/2017           NaN  10/01/2017 22:10:56     001  \n",
       "4       0  0,00   01/01/2017           NaN  11/01/2017 21:59:16     001  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26651/459522789.py:1: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  merged_df['Arrival'] = pd.to_datetime(merged_df['Arrival'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151852</th>\n",
       "      <td>19887FIHJR22</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>22/10/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3080,00</td>\n",
       "      <td>11/03/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>11/03/2023 10:15:06</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151853</th>\n",
       "      <td>19887DOSJP23</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>12/06/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>2112,00</td>\n",
       "      <td>17/03/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>17/03/2023 17:33:23</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151849</th>\n",
       "      <td>19887VFAUN19</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>28/09/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>1760,00</td>\n",
       "      <td>02/02/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>02/02/2023 16:43:04</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151856</th>\n",
       "      <td>19887IENNC26</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>21/09/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3168,00</td>\n",
       "      <td>03/06/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>03/06/2023 12:55:03</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151850</th>\n",
       "      <td>19887VNOHO20</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>27/08/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>1496,00</td>\n",
       "      <td>09/03/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>09/03/2023 20:00:03</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Code      Status BookingChannel    Arrival   Departure  \\\n",
       "151852  19887FIHJR22  Confermata           Sito 2023-10-19  22/10/2023   \n",
       "151853  19887DOSJP23  Confermata           Sito 2023-10-06  12/06/2023   \n",
       "151849  19887VFAUN19  Confermata           Sito 2023-09-26  28/09/2023   \n",
       "151856  19887IENNC26  Confermata           Sito 2023-09-18  21/09/2023   \n",
       "151850  19887VNOHO20  Confermata           Sito 2023-08-25  27/08/2023   \n",
       "\n",
       "        Nights    Total PurchaseDate BookingDevice         LastModified  \\\n",
       "151852       3  3080,00   11/03/2023       Website  11/03/2023 10:15:06   \n",
       "151853       2  2112,00   17/03/2023       Website  17/03/2023 17:33:23   \n",
       "151849       2  1760,00   02/02/2023       Website  02/02/2023 16:43:04   \n",
       "151856       3  3168,00   03/06/2023       Website  03/06/2023 12:55:03   \n",
       "151850       2  1496,00   09/03/2023       Website  09/03/2023 20:00:03   \n",
       "\n",
       "       HotelId  \n",
       "151852     010  \n",
       "151853     010  \n",
       "151849     010  \n",
       "151856     010  \n",
       "151850     010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Arrival'] = pd.to_datetime(merged_df['Arrival'])\n",
    "# Sorting by 'Arrival' column in descending order\n",
    "sorted_bookings_df = merged_df.sort_values(by='Arrival', ascending=False)\n",
    "# Filtering for HotelId '001'\n",
    "filtered_df = sorted_bookings_df.loc[sorted_bookings_df['HotelId'] == '010']\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I convert datates to timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN in 'Arrival': 0\n",
      "Rows with NaN in 'Departure': 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "      <th>Arrival_Timestamp</th>\n",
       "      <th>Departure_Timestamp</th>\n",
       "      <th>LastModified_Timestamp</th>\n",
       "      <th>Purchase_Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60363</th>\n",
       "      <td>16134HN15330</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>2024-02-18</td>\n",
       "      <td>7</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>Website</td>\n",
       "      <td>2023-03-22 23:03:58</td>\n",
       "      <td>006</td>\n",
       "      <td>1730505600000000000</td>\n",
       "      <td>1708214400000000000</td>\n",
       "      <td>2023-03-22 23:03:58</td>\n",
       "      <td>1679443200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60681</th>\n",
       "      <td>3379360609/4257615568</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-20 10:06:11</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-05-20 10:06:11</td>\n",
       "      <td>1684540800000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60413</th>\n",
       "      <td>2640244691/4170868985</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>4887.0</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-01 14:27:37</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:27:37</td>\n",
       "      <td>1680307200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60411</th>\n",
       "      <td>2641625582/4170854126</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>1968.3</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>1680307200000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60410</th>\n",
       "      <td>2641625582/4170854114</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>1871.1</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>1680307200000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Code      Status BookingChannel    Arrival  Departure  \\\n",
       "60363           16134HN15330  Confermata           Sito 2024-11-02 2024-02-18   \n",
       "60681  3379360609/4257615568  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60413  2640244691/4170868985  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60411  2641625582/4170854126  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60410  2641625582/4170854114  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "\n",
       "       Nights   Total PurchaseDate BookingDevice        LastModified HotelId  \\\n",
       "60363       7  3208.0   2023-03-22       Website 2023-03-22 23:03:58     006   \n",
       "60681       7  5130.0   2023-05-20           NaN 2023-05-20 10:06:11     006   \n",
       "60413       7  4887.0   2023-04-01           NaN 2023-04-01 14:27:37     006   \n",
       "60411       7  1968.3   2023-04-01           NaN 2023-04-01 14:17:14     006   \n",
       "60410       7  1871.1   2023-04-01           NaN 2023-04-01 14:17:14     006   \n",
       "\n",
       "         Arrival_Timestamp  Departure_Timestamp LastModified_Timestamp  \\\n",
       "60363  1730505600000000000  1708214400000000000    2023-03-22 23:03:58   \n",
       "60681  1727827200000000000  1708128000000000000    2023-05-20 10:06:11   \n",
       "60413  1727827200000000000  1708128000000000000    2023-04-01 14:27:37   \n",
       "60411  1727827200000000000  1708128000000000000    2023-04-01 14:17:14   \n",
       "60410  1727827200000000000  1708128000000000000    2023-04-01 14:17:14   \n",
       "\n",
       "        Purchase_Timestamp  \n",
       "60363  1679443200000000000  \n",
       "60681  1684540800000000000  \n",
       "60413  1680307200000000000  \n",
       "60411  1680307200000000000  \n",
       "60410  1680307200000000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering for HotelId '001'\n",
    "nan_rows = sorted_bookings_df[sorted_bookings_df['Arrival'].isna()]\n",
    "print(\"Rows with NaN in 'Arrival':\", len(nan_rows))\n",
    "nan_rows = sorted_bookings_df[sorted_bookings_df['Departure'].isna()]\n",
    "print(\"Rows with NaN in 'Departure':\", len(nan_rows))\n",
    "# conversion in datetime\n",
    "sorted_bookings_df['Arrival'] = pd.to_datetime(sorted_bookings_df['Arrival'], errors='coerce', dayfirst=True)\n",
    "sorted_bookings_df['Departure'] = pd.to_datetime(sorted_bookings_df['Departure'], errors='coerce', dayfirst=True)\n",
    "sorted_bookings_df['LastModified'] = pd.to_datetime(sorted_bookings_df['LastModified'], errors='coerce', dayfirst=True)\n",
    "sorted_bookings_df['PurchaseDate'] = pd.to_datetime(sorted_bookings_df['PurchaseDate'], errors='coerce', dayfirst=True)\n",
    "# we want to make sure that are numerical data\n",
    "sorted_bookings_df['Total'] = sorted_bookings_df['Total'].str.replace(',', '.').astype(float)\n",
    "sorted_bookings_df['Total'] = pd.to_numeric(sorted_bookings_df['Total'])\n",
    "sorted_bookings_df['Nights'] = pd.to_numeric(sorted_bookings_df['Nights'])\n",
    "# add timestamp\n",
    "sorted_bookings_df['Arrival_Timestamp'] = sorted_bookings_df['Arrival'].astype('int64')\n",
    "sorted_bookings_df['Departure_Timestamp'] = sorted_bookings_df['Departure'].astype('int64')\n",
    "sorted_bookings_df['LastModified_Timestamp'] = pd.to_datetime(sorted_bookings_df['LastModified'], errors='coerce')\n",
    "sorted_bookings_df['Purchase_Timestamp'] = sorted_bookings_df['PurchaseDate'].astype('int64')\n",
    "sorted_bookings_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to add the city to he dataset the client has provided the following mapping:\n",
    "```\n",
    "hotel_to_city = {\n",
    "    '001': \"Rome, Italu\",\n",
    "    '002': \"Naples, Italy\",\n",
    "    '003': \"Florence, Italy\",\n",
    "    '004': \"Florence, Italy\",\n",
    "    '005': \"Naples, Italy\",\n",
    "    '006': \"Brindisi, Italy\",\n",
    "    '007': \"Latina, Italy\",\n",
    "    '008': \"Olbia, Sardinia, Italy\",\n",
    "    '009': \"Chamonix-Mont-Blanc, France\",\n",
    "    '010': \"Rome, Italy\",\n",
    "}\n",
    "```\n",
    "So we can have a complete a dataset to correlate in future with events, weather and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_to_city = {\n",
    "    '001': \"Rome\",\n",
    "    '002': \"Naples\",\n",
    "    '003': \"Florence\",\n",
    "    '004': \"Florence\",\n",
    "    '005': \"Naples\",\n",
    "    '006': \"Brindisi\",\n",
    "    '007': \"Latina\",\n",
    "    '008': \"Olbia\",\n",
    "    '009': \"Chamonix-Mont-Blanc\",\n",
    "    '010': \"Rome\",\n",
    "}\n",
    "\n",
    "# Function to get the city name based on HotelId\n",
    "def get_city(hotel_id):\n",
    "    return coordinate_to_city.get(hotel_id, \"Unknown\")\n",
    "\n",
    "# Add the City column based on the HotelId\n",
    "sorted_bookings_df['City'] = sorted_bookings_df['HotelId'].apply(get_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want also add the season because we know from the domain the booking changes of season and when the booking device is not known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "      <th>Arrival_Timestamp</th>\n",
       "      <th>Departure_Timestamp</th>\n",
       "      <th>LastModified_Timestamp</th>\n",
       "      <th>Purchase_Timestamp</th>\n",
       "      <th>City</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60363</th>\n",
       "      <td>16134HN15330</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>2024-02-18</td>\n",
       "      <td>7</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>Website</td>\n",
       "      <td>2023-03-22 23:03:58</td>\n",
       "      <td>006</td>\n",
       "      <td>1730505600000000000</td>\n",
       "      <td>1708214400000000000</td>\n",
       "      <td>2023-03-22 23:03:58</td>\n",
       "      <td>1679443200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60681</th>\n",
       "      <td>3379360609/4257615568</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-05-20 10:06:11</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-05-20 10:06:11</td>\n",
       "      <td>1684540800000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60413</th>\n",
       "      <td>2640244691/4170868985</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>4887.0</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-01 14:27:37</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:27:37</td>\n",
       "      <td>1680307200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60411</th>\n",
       "      <td>2641625582/4170854126</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>1968.3</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>1680307200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60410</th>\n",
       "      <td>2641625582/4170854114</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>1871.1</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>1680307200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Code      Status BookingChannel    Arrival  Departure  \\\n",
       "60363           16134HN15330  Confermata           Sito 2024-11-02 2024-02-18   \n",
       "60681  3379360609/4257615568  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60413  2640244691/4170868985  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60411  2641625582/4170854126  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60410  2641625582/4170854114  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "\n",
       "       Nights   Total PurchaseDate BookingDevice        LastModified HotelId  \\\n",
       "60363       7  3208.0   2023-03-22       Website 2023-03-22 23:03:58     006   \n",
       "60681       7  5130.0   2023-05-20       Unknown 2023-05-20 10:06:11     006   \n",
       "60413       7  4887.0   2023-04-01       Unknown 2023-04-01 14:27:37     006   \n",
       "60411       7  1968.3   2023-04-01       Unknown 2023-04-01 14:17:14     006   \n",
       "60410       7  1871.1   2023-04-01       Unknown 2023-04-01 14:17:14     006   \n",
       "\n",
       "         Arrival_Timestamp  Departure_Timestamp LastModified_Timestamp  \\\n",
       "60363  1730505600000000000  1708214400000000000    2023-03-22 23:03:58   \n",
       "60681  1727827200000000000  1708128000000000000    2023-05-20 10:06:11   \n",
       "60413  1727827200000000000  1708128000000000000    2023-04-01 14:27:37   \n",
       "60411  1727827200000000000  1708128000000000000    2023-04-01 14:17:14   \n",
       "60410  1727827200000000000  1708128000000000000    2023-04-01 14:17:14   \n",
       "\n",
       "        Purchase_Timestamp      City Season  \n",
       "60363  1679443200000000000  Brindisi   Fall  \n",
       "60681  1684540800000000000  Brindisi   Fall  \n",
       "60413  1680307200000000000  Brindisi   Fall  \n",
       "60411  1680307200000000000  Brindisi   Fall  \n",
       "60410  1680307200000000000  Brindisi   Fall  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we clean unknown\n",
    "sorted_bookings_df['BookingDevice'].fillna('Unknown', inplace=True)\n",
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "sorted_bookings_df['Season'] = sorted_bookings_df['Arrival'].apply(get_season)\n",
    "sorted_bookings_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before going further and doing descriptive statistics we neeed to know is there are still NaN. It is ok we store for future purposes the dataset in parquet file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the DataFrame contain any NaN values? True\n",
      "Rows with NaN values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "      <th>Arrival_Timestamp</th>\n",
       "      <th>Departure_Timestamp</th>\n",
       "      <th>LastModified_Timestamp</th>\n",
       "      <th>Purchase_Timestamp</th>\n",
       "      <th>City</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44934</th>\n",
       "      <td>RDK00025294-SE</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-06-25</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-06-25 18:42:22</td>\n",
       "      <td>005</td>\n",
       "      <td>1701907200000000000</td>\n",
       "      <td>1689379200000000000</td>\n",
       "      <td>2023-06-25 18:42:22</td>\n",
       "      <td>1687651200000000000</td>\n",
       "      <td>Naples</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44933</th>\n",
       "      <td>RDK00025294-SE</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>2023-07-15</td>\n",
       "      <td>3</td>\n",
       "      <td>656.64</td>\n",
       "      <td>2023-06-25</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-06-25 18:42:22</td>\n",
       "      <td>005</td>\n",
       "      <td>1701907200000000000</td>\n",
       "      <td>1689379200000000000</td>\n",
       "      <td>2023-06-25 18:42:22</td>\n",
       "      <td>1687651200000000000</td>\n",
       "      <td>Naples</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44385</th>\n",
       "      <td>RDK00014771-A35343-25660-13565848-Secret Escapes</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>2023-05-17</td>\n",
       "      <td>5</td>\n",
       "      <td>1257.22</td>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-12 15:58:19</td>\n",
       "      <td>005</td>\n",
       "      <td>1701734400000000000</td>\n",
       "      <td>1684281600000000000</td>\n",
       "      <td>2023-04-12 15:58:19</td>\n",
       "      <td>1681257600000000000</td>\n",
       "      <td>Naples</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44366</th>\n",
       "      <td>RDK00014459-A35343-21410-13541714-Secret Escapes</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-10 19:52:26</td>\n",
       "      <td>005</td>\n",
       "      <td>1701734400000000000</td>\n",
       "      <td>1683936000000000000</td>\n",
       "      <td>2023-04-10 19:52:26</td>\n",
       "      <td>1681084800000000000</td>\n",
       "      <td>Naples</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44365</th>\n",
       "      <td>RDK00014459-A35343-21410-13541714-Secret Escapes</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>1</td>\n",
       "      <td>199.68</td>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-10 19:52:26</td>\n",
       "      <td>005</td>\n",
       "      <td>1701734400000000000</td>\n",
       "      <td>1683936000000000000</td>\n",
       "      <td>2023-04-10 19:52:26</td>\n",
       "      <td>1681084800000000000</td>\n",
       "      <td>Naples</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Code      Status  \\\n",
       "44934                                    RDK00025294-SE  Cancellata   \n",
       "44933                                    RDK00025294-SE  Confermata   \n",
       "44385  RDK00014771-A35343-25660-13565848-Secret Escapes  Confermata   \n",
       "44366  RDK00014459-A35343-21410-13541714-Secret Escapes  Cancellata   \n",
       "44365  RDK00014459-A35343-21410-13541714-Secret Escapes  Confermata   \n",
       "\n",
       "      BookingChannel    Arrival  Departure  Nights    Total PurchaseDate  \\\n",
       "44934            NaN 2023-12-07 2023-07-15       0     0.00   2023-06-25   \n",
       "44933            NaN 2023-12-07 2023-07-15       3   656.64   2023-06-25   \n",
       "44385            NaN 2023-12-05 2023-05-17       5  1257.22   2023-04-12   \n",
       "44366            NaN 2023-12-05 2023-05-13       0     0.00   2023-04-10   \n",
       "44365            NaN 2023-12-05 2023-05-13       1   199.68   2023-04-10   \n",
       "\n",
       "      BookingDevice        LastModified HotelId    Arrival_Timestamp  \\\n",
       "44934       Unknown 2023-06-25 18:42:22     005  1701907200000000000   \n",
       "44933       Unknown 2023-06-25 18:42:22     005  1701907200000000000   \n",
       "44385       Unknown 2023-04-12 15:58:19     005  1701734400000000000   \n",
       "44366       Unknown 2023-04-10 19:52:26     005  1701734400000000000   \n",
       "44365       Unknown 2023-04-10 19:52:26     005  1701734400000000000   \n",
       "\n",
       "       Departure_Timestamp LastModified_Timestamp   Purchase_Timestamp  \\\n",
       "44934  1689379200000000000    2023-06-25 18:42:22  1687651200000000000   \n",
       "44933  1689379200000000000    2023-06-25 18:42:22  1687651200000000000   \n",
       "44385  1684281600000000000    2023-04-12 15:58:19  1681257600000000000   \n",
       "44366  1683936000000000000    2023-04-10 19:52:26  1681084800000000000   \n",
       "44365  1683936000000000000    2023-04-10 19:52:26  1681084800000000000   \n",
       "\n",
       "         City  Season  \n",
       "44934  Naples  Winter  \n",
       "44933  Naples  Winter  \n",
       "44385  Naples  Winter  \n",
       "44366  Naples  Winter  \n",
       "44365  Naples  Winter  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any row in any column is NaN\n",
    "has_nan = sorted_bookings_df.isna().any().any()\n",
    "print(f\"Does the DataFrame contain any NaN values? {has_nan}\")\n",
    "# Display rows with any NaN values\n",
    "rows_with_nan = sorted_bookings_df[sorted_bookings_df.isna().any(axis=1)]\n",
    "print(\"Rows with NaN values:\")\n",
    "rows_with_nan.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. We've seen that the booking channel can be a valid string or Unknown. The other thing that we want is to the hotel booking for a fixed period from 2024 to 2022. After this we can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "      <th>Arrival_Timestamp</th>\n",
       "      <th>Departure_Timestamp</th>\n",
       "      <th>LastModified_Timestamp</th>\n",
       "      <th>Purchase_Timestamp</th>\n",
       "      <th>City</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60363</th>\n",
       "      <td>16134HN15330</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>2024-02-18</td>\n",
       "      <td>7</td>\n",
       "      <td>3208.0</td>\n",
       "      <td>2023-03-22</td>\n",
       "      <td>Website</td>\n",
       "      <td>2023-03-22 23:03:58</td>\n",
       "      <td>006</td>\n",
       "      <td>1730505600000000000</td>\n",
       "      <td>1708214400000000000</td>\n",
       "      <td>2023-03-22 23:03:58</td>\n",
       "      <td>1679443200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60681</th>\n",
       "      <td>3379360609/4257615568</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>2023-05-20</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-05-20 10:06:11</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-05-20 10:06:11</td>\n",
       "      <td>1684540800000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60413</th>\n",
       "      <td>2640244691/4170868985</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>4887.0</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-01 14:27:37</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:27:37</td>\n",
       "      <td>1680307200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60411</th>\n",
       "      <td>2641625582/4170854126</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>1968.3</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>1680307200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60410</th>\n",
       "      <td>2641625582/4170854114</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-10-02</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>1871.1</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>006</td>\n",
       "      <td>1727827200000000000</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>2023-04-01 14:17:14</td>\n",
       "      <td>1680307200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Code      Status BookingChannel    Arrival  Departure  \\\n",
       "60363           16134HN15330  Confermata           Sito 2024-11-02 2024-02-18   \n",
       "60681  3379360609/4257615568  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60413  2640244691/4170868985  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60411  2641625582/4170854126  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "60410  2641625582/4170854114  Confermata    Booking.com 2024-10-02 2024-02-17   \n",
       "\n",
       "       Nights   Total PurchaseDate BookingDevice        LastModified HotelId  \\\n",
       "60363       7  3208.0   2023-03-22       Website 2023-03-22 23:03:58     006   \n",
       "60681       7  5130.0   2023-05-20       Unknown 2023-05-20 10:06:11     006   \n",
       "60413       7  4887.0   2023-04-01       Unknown 2023-04-01 14:27:37     006   \n",
       "60411       7  1968.3   2023-04-01       Unknown 2023-04-01 14:17:14     006   \n",
       "60410       7  1871.1   2023-04-01       Unknown 2023-04-01 14:17:14     006   \n",
       "\n",
       "         Arrival_Timestamp  Departure_Timestamp LastModified_Timestamp  \\\n",
       "60363  1730505600000000000  1708214400000000000    2023-03-22 23:03:58   \n",
       "60681  1727827200000000000  1708128000000000000    2023-05-20 10:06:11   \n",
       "60413  1727827200000000000  1708128000000000000    2023-04-01 14:27:37   \n",
       "60411  1727827200000000000  1708128000000000000    2023-04-01 14:17:14   \n",
       "60410  1727827200000000000  1708128000000000000    2023-04-01 14:17:14   \n",
       "\n",
       "        Purchase_Timestamp      City Season  \n",
       "60363  1679443200000000000  Brindisi   Fall  \n",
       "60681  1684540800000000000  Brindisi   Fall  \n",
       "60413  1680307200000000000  Brindisi   Fall  \n",
       "60411  1680307200000000000  Brindisi   Fall  \n",
       "60410  1680307200000000000  Brindisi   Fall  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_bookings_df['BookingChannel'] = sorted_bookings_df['BookingChannel'].fillna('Unknown')\n",
    "sorted_bookings_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to restrict the timing interval between 2020 and 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the DataFrame contain any NaN values? False\n",
      "The dataset is ready some descriptivre statistics\n"
     ]
    }
   ],
   "source": [
    "start_date = '2020-01-01'\n",
    "end_date = '2024-02-28'\n",
    "sorted_bookings_df.head()\n",
    "datetime_columns = ['Arrival', 'Departure', 'PurchaseDate', 'LastModified']\n",
    "for col in datetime_columns:\n",
    "    sorted_bookings_df[col] = pd.to_datetime(sorted_bookings_df[col])\n",
    "hb_dataset = sorted_bookings_df[(sorted_bookings_df['Arrival'] >= start_date) & (sorted_bookings_df['Arrival'] <= end_date)] \n",
    "# Check if any row in any column is NaN\n",
    "has_nan = hb_dataset.isna().any().any()\n",
    "print(f\"Does the DataFrame contain any NaN values? {has_nan}\")\n",
    "if has_nan:\n",
    "# Display rows with any NaN values\n",
    "    rows_with_nan = hb_dataset[hb_dataset.isna().any(axis=1)]\n",
    "    print(\"Rows with NaN values:\")\n",
    "    rows_with_nan.head()\n",
    "else:\n",
    "    print('The dataset is ready some descriptivre statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame saved to filtered_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save the filtered DataFrame to a Parquet file\n",
    "parquet_file = 'filtered_data.parquet'\n",
    "hb_dataset.to_parquet(parquet_file)\n",
    "print(f\"Filtered DataFrame saved to {parquet_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "      <th>Arrival_Timestamp</th>\n",
       "      <th>Departure_Timestamp</th>\n",
       "      <th>LastModified_Timestamp</th>\n",
       "      <th>Purchase_Timestamp</th>\n",
       "      <th>City</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60596</th>\n",
       "      <td>2708236755/4234197239</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>7</td>\n",
       "      <td>3134.70</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-05-07 09:39:59</td>\n",
       "      <td>006</td>\n",
       "      <td>1708732800000000000</td>\n",
       "      <td>1709337600000000000</td>\n",
       "      <td>2023-05-07 09:39:59</td>\n",
       "      <td>1683417600000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60595</th>\n",
       "      <td>2366509110/4234190518</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-05-07 09:33:58</td>\n",
       "      <td>006</td>\n",
       "      <td>1708732800000000000</td>\n",
       "      <td>1709337600000000000</td>\n",
       "      <td>2023-05-07 09:33:58</td>\n",
       "      <td>1683417600000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60341</th>\n",
       "      <td>2340590757/4148039829</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-03-19 10:37:54</td>\n",
       "      <td>006</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>1708732800000000000</td>\n",
       "      <td>2023-03-19 10:37:54</td>\n",
       "      <td>1679184000000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60340</th>\n",
       "      <td>2340590757/4148039863</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-03-19 10:37:54</td>\n",
       "      <td>006</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>1708732800000000000</td>\n",
       "      <td>2023-03-19 10:37:54</td>\n",
       "      <td>1679184000000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60339</th>\n",
       "      <td>2340590757/4148039844</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-03-19 10:37:54</td>\n",
       "      <td>006</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>1708732800000000000</td>\n",
       "      <td>2023-03-19 10:37:54</td>\n",
       "      <td>1679184000000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60269</th>\n",
       "      <td>16134FG15230</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>7</td>\n",
       "      <td>3507.00</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>Website</td>\n",
       "      <td>2023-03-07 21:29:22</td>\n",
       "      <td>006</td>\n",
       "      <td>1708128000000000000</td>\n",
       "      <td>1708732800000000000</td>\n",
       "      <td>2023-03-07 21:29:22</td>\n",
       "      <td>1678147200000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60417</th>\n",
       "      <td>3051523557/4172280874</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-03</td>\n",
       "      <td>2024-03-08</td>\n",
       "      <td>6</td>\n",
       "      <td>2515.05</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-02 11:34:34</td>\n",
       "      <td>006</td>\n",
       "      <td>1706918400000000000</td>\n",
       "      <td>1709856000000000000</td>\n",
       "      <td>2023-04-02 11:34:34</td>\n",
       "      <td>1680393600000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60313</th>\n",
       "      <td>2771190332/4142120223</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-03-15 18:50:09</td>\n",
       "      <td>006</td>\n",
       "      <td>1706745600000000000</td>\n",
       "      <td>1704585600000000000</td>\n",
       "      <td>2023-03-15 18:50:09</td>\n",
       "      <td>1678838400000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60312</th>\n",
       "      <td>2722531194/4142090827</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-03-15 18:31:58</td>\n",
       "      <td>006</td>\n",
       "      <td>1706745600000000000</td>\n",
       "      <td>1704585600000000000</td>\n",
       "      <td>2023-03-15 18:31:58</td>\n",
       "      <td>1678838400000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60314</th>\n",
       "      <td>2771190332/4142120207</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-03-15 18:50:09</td>\n",
       "      <td>006</td>\n",
       "      <td>1706745600000000000</td>\n",
       "      <td>1704585600000000000</td>\n",
       "      <td>2023-03-15 18:50:09</td>\n",
       "      <td>1678838400000000000</td>\n",
       "      <td>Brindisi</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Code      Status BookingChannel    Arrival  Departure  \\\n",
       "60596  2708236755/4234197239  Confermata    Booking.com 2024-02-24 2024-03-02   \n",
       "60595  2366509110/4234190518  Cancellata    Booking.com 2024-02-24 2024-03-02   \n",
       "60341  2340590757/4148039829  Cancellata    Booking.com 2024-02-17 2024-02-24   \n",
       "60340  2340590757/4148039863  Cancellata    Booking.com 2024-02-17 2024-02-24   \n",
       "60339  2340590757/4148039844  Cancellata    Booking.com 2024-02-17 2024-02-24   \n",
       "60269           16134FG15230  Confermata           Sito 2024-02-17 2024-02-24   \n",
       "60417  3051523557/4172280874  Confermata    Booking.com 2024-02-03 2024-03-08   \n",
       "60313  2771190332/4142120223  Cancellata    Booking.com 2024-02-01 2024-01-07   \n",
       "60312  2722531194/4142090827  Cancellata    Booking.com 2024-02-01 2024-01-07   \n",
       "60314  2771190332/4142120207  Cancellata    Booking.com 2024-02-01 2024-01-07   \n",
       "\n",
       "       Nights    Total PurchaseDate BookingDevice        LastModified HotelId  \\\n",
       "60596       7  3134.70   2023-05-07       Unknown 2023-05-07 09:39:59     006   \n",
       "60595       0     0.00   2023-05-07       Unknown 2023-05-07 09:33:58     006   \n",
       "60341       0     0.00   2023-03-19       Unknown 2023-03-19 10:37:54     006   \n",
       "60340       0     0.00   2023-03-19       Unknown 2023-03-19 10:37:54     006   \n",
       "60339       0     0.00   2023-03-19       Unknown 2023-03-19 10:37:54     006   \n",
       "60269       7  3507.00   2023-03-07       Website 2023-03-07 21:29:22     006   \n",
       "60417       6  2515.05   2023-04-02       Unknown 2023-04-02 11:34:34     006   \n",
       "60313       0     0.00   2023-03-15       Unknown 2023-03-15 18:50:09     006   \n",
       "60312       0     0.00   2023-03-15       Unknown 2023-03-15 18:31:58     006   \n",
       "60314       0     0.00   2023-03-15       Unknown 2023-03-15 18:50:09     006   \n",
       "\n",
       "         Arrival_Timestamp  Departure_Timestamp LastModified_Timestamp  \\\n",
       "60596  1708732800000000000  1709337600000000000    2023-05-07 09:39:59   \n",
       "60595  1708732800000000000  1709337600000000000    2023-05-07 09:33:58   \n",
       "60341  1708128000000000000  1708732800000000000    2023-03-19 10:37:54   \n",
       "60340  1708128000000000000  1708732800000000000    2023-03-19 10:37:54   \n",
       "60339  1708128000000000000  1708732800000000000    2023-03-19 10:37:54   \n",
       "60269  1708128000000000000  1708732800000000000    2023-03-07 21:29:22   \n",
       "60417  1706918400000000000  1709856000000000000    2023-04-02 11:34:34   \n",
       "60313  1706745600000000000  1704585600000000000    2023-03-15 18:50:09   \n",
       "60312  1706745600000000000  1704585600000000000    2023-03-15 18:31:58   \n",
       "60314  1706745600000000000  1704585600000000000    2023-03-15 18:50:09   \n",
       "\n",
       "        Purchase_Timestamp      City  Season  \n",
       "60596  1683417600000000000  Brindisi  Winter  \n",
       "60595  1683417600000000000  Brindisi  Winter  \n",
       "60341  1679184000000000000  Brindisi  Winter  \n",
       "60340  1679184000000000000  Brindisi  Winter  \n",
       "60339  1679184000000000000  Brindisi  Winter  \n",
       "60269  1678147200000000000  Brindisi  Winter  \n",
       "60417  1680393600000000000  Brindisi  Winter  \n",
       "60313  1678838400000000000  Brindisi  Winter  \n",
       "60312  1678838400000000000  Brindisi  Winter  \n",
       "60314  1678838400000000000  Brindisi  Winter  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb_dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here we start to to understand the categories Status and Booking devices and use an Ordinal encoder. Our expectation is for the status are the categories: Confermata(Confirmed), Cancellata(Cancelled), Modificata(Modified). This later will be useful for cancellation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "status_categories = hb_dataset[['Status']]\n",
    "device_categorues = hb_dataset[['BookingDevice']]\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "hb_dataset_encoded = ordinal_encoder.fit_transform(status_categories)\n",
    "hb_dataset['Status'] = hb_dataset_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descriptive statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Confermata', 'Cancellata', 'Modificata'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb_dataset['Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown', 'Website', 'Mobile', 'Tablet'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hb_dataset['BookingDevice'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive Statistics for numeric columns in the filtered DataFrame:\n",
      "             Nights         Total  Arrival_Timestamp  Departure_Timestamp  \\\n",
      "count  39375.000000  39375.000000       3.937500e+04         3.937500e+04   \n",
      "mean       1.517663    396.484267       1.641716e+18         1.642539e+18   \n",
      "std        1.969103    668.298718       3.285898e+16         3.243173e+16   \n",
      "min        0.000000      0.000000       1.577837e+18         1.577923e+18   \n",
      "25%        0.000000      0.000000       1.615853e+18         1.622938e+18   \n",
      "50%        1.000000    144.900000       1.649549e+18         1.651363e+18   \n",
      "75%        2.000000    531.515000       1.665014e+18         1.664323e+18   \n",
      "max       30.000000  20124.000000       1.708733e+18         1.709856e+18   \n",
      "\n",
      "       Purchase_Timestamp  \n",
      "count        3.937500e+04  \n",
      "mean         1.636303e+18  \n",
      "std          3.340110e+16  \n",
      "min          1.553213e+18  \n",
      "25%          1.612829e+18  \n",
      "50%          1.645229e+18  \n",
      "75%          1.661299e+18  \n",
      "max          1.688256e+18  \n",
      "\n",
      "Descriptive Statistics for all columns in the filtered DataFrame:\n",
      "                   Code      Status BookingChannel              Arrival  \\\n",
      "count             39375       39375          39375                39375   \n",
      "unique            36774           3             57                 1399   \n",
      "top     M41DPG/554481/1  Confermata    Booking.com  2020-09-24 00:00:00   \n",
      "freq                 13       21869          23416                  146   \n",
      "first               NaN         NaN            NaN  2020-01-01 00:00:00   \n",
      "last                NaN         NaN            NaN  2024-02-24 00:00:00   \n",
      "mean                NaN         NaN            NaN                  NaN   \n",
      "std                 NaN         NaN            NaN                  NaN   \n",
      "min                 NaN         NaN            NaN                  NaN   \n",
      "25%                 NaN         NaN            NaN                  NaN   \n",
      "50%                 NaN         NaN            NaN                  NaN   \n",
      "75%                 NaN         NaN            NaN                  NaN   \n",
      "max                 NaN         NaN            NaN                  NaN   \n",
      "\n",
      "                  Departure        Nights         Total         PurchaseDate  \\\n",
      "count                 39375  39375.000000  39375.000000                39375   \n",
      "unique                 1398           NaN           NaN                 1480   \n",
      "top     2020-09-27 00:00:00           NaN           NaN  2020-01-28 00:00:00   \n",
      "freq                    183           NaN           NaN                  143   \n",
      "first   2020-01-02 00:00:00           NaN           NaN  2019-03-22 00:00:00   \n",
      "last    2024-03-08 00:00:00           NaN           NaN  2023-07-02 00:00:00   \n",
      "mean                    NaN      1.517663    396.484267                  NaN   \n",
      "std                     NaN      1.969103    668.298718                  NaN   \n",
      "min                     NaN      0.000000      0.000000                  NaN   \n",
      "25%                     NaN      0.000000      0.000000                  NaN   \n",
      "50%                     NaN      1.000000    144.900000                  NaN   \n",
      "75%                     NaN      2.000000    531.515000                  NaN   \n",
      "max                     NaN     30.000000  20124.000000                  NaN   \n",
      "\n",
      "       BookingDevice         LastModified HotelId  Arrival_Timestamp  \\\n",
      "count          39375                39375   39375       3.937500e+04   \n",
      "unique             4                32391      10                NaN   \n",
      "top          Unknown  2020-01-28 22:26:38     008                NaN   \n",
      "freq           33093                   24   10720                NaN   \n",
      "first            NaN  2019-03-22 12:49:30     NaN                NaN   \n",
      "last             NaN  2023-07-02 22:29:40     NaN                NaN   \n",
      "mean             NaN                  NaN     NaN       1.641716e+18   \n",
      "std              NaN                  NaN     NaN       3.285898e+16   \n",
      "min              NaN                  NaN     NaN       1.577837e+18   \n",
      "25%              NaN                  NaN     NaN       1.615853e+18   \n",
      "50%              NaN                  NaN     NaN       1.649549e+18   \n",
      "75%              NaN                  NaN     NaN       1.665014e+18   \n",
      "max              NaN                  NaN     NaN       1.708733e+18   \n",
      "\n",
      "        Departure_Timestamp LastModified_Timestamp  Purchase_Timestamp   City  \\\n",
      "count          3.937500e+04                  39375        3.937500e+04  39375   \n",
      "unique                  NaN                  32391                 NaN      7   \n",
      "top                     NaN    2020-01-28 22:26:38                 NaN  Olbia   \n",
      "freq                    NaN                     24                 NaN  10720   \n",
      "first                   NaN    2019-03-22 12:49:30                 NaN    NaN   \n",
      "last                    NaN    2023-07-02 22:29:40                 NaN    NaN   \n",
      "mean           1.642539e+18                    NaN        1.636303e+18    NaN   \n",
      "std            3.243173e+16                    NaN        3.340110e+16    NaN   \n",
      "min            1.577923e+18                    NaN        1.553213e+18    NaN   \n",
      "25%            1.622938e+18                    NaN        1.612829e+18    NaN   \n",
      "50%            1.651363e+18                    NaN        1.645229e+18    NaN   \n",
      "75%            1.664323e+18                    NaN        1.661299e+18    NaN   \n",
      "max            1.709856e+18                    NaN        1.688256e+18    NaN   \n",
      "\n",
      "        Season  \n",
      "count    39375  \n",
      "unique       4  \n",
      "top     Summer  \n",
      "freq     13869  \n",
      "first      NaN  \n",
      "last       NaN  \n",
      "mean       NaN  \n",
      "std        NaN  \n",
      "min        NaN  \n",
      "25%        NaN  \n",
      "50%        NaN  \n",
      "75%        NaN  \n",
      "max        NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26651/2572938487.py:5: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  descriptive_stats_all = hb_dataset.describe(include='all')\n",
      "/tmp/ipykernel_26651/2572938487.py:5: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  descriptive_stats_all = hb_dataset.describe(include='all')\n",
      "/tmp/ipykernel_26651/2572938487.py:5: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  descriptive_stats_all = hb_dataset.describe(include='all')\n",
      "/tmp/ipykernel_26651/2572938487.py:5: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  descriptive_stats_all = hb_dataset.describe(include='all')\n",
      "/tmp/ipykernel_26651/2572938487.py:5: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  descriptive_stats_all = hb_dataset.describe(include='all')\n"
     ]
    }
   ],
   "source": [
    "# For numeric columns only\n",
    "descriptive_stats = hb_dataset.describe()\n",
    "print(\"\\nDescriptive Statistics for numeric columns in the filtered DataFrame:\")\n",
    "print(descriptive_stats)\n",
    "descriptive_stats_all = hb_dataset.describe(include='all')\n",
    "print(\"\\nDescriptive Statistics for all columns in the filtered DataFrame:\")\n",
    "print(descriptive_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that:\n",
    "- We've 39375 booking in the period.\n",
    "- The average staying is 1.6 days for each booking.\n",
    "- The medium booking revenue is 370 euros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3637064869.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Here we want to plot the dat\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Distributon of the data\n",
    "Here we want to plot the dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "That's not enough, we want to know:\n",
    "- How frequent is a booking?\n",
    "- Which between our customers how had most revenue?\n",
    "- Which has most room booked and and in which city?\n",
    "- Which is the season in which we've most rooom booked? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-01-01'\n",
    "end_date = '2024-12-31'\n",
    "filtered_df = hb_dataset[(hb_dataset['PurchaseDate'] >= start_date) & (hb_dataset['PurchaseDate'] <= end_date)]\n",
    "\n",
    "# Plot the distribution of purchase dates using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(filtered_df['PurchaseDate'], kde=True, bins=30)\n",
    "plt.xlabel('Purchase Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Purchase Dates (2020-2024)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(filtered_df['Arrival'], kde=True, bins=30)\n",
    "plt.xlabel('Arrival Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Arrival Dates (2020-2024)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sense. Most booking are at the beginning of the year and just before summer. Italians tends to go in vacation on August so in July the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'PurchaseDate' to ordinal for fitting distributions\n",
    "purchase_dates = hb_dataset['PurchaseDate'].apply(lambda x: x.toordinal())\n",
    "\n",
    "# List of distributions to check\n",
    "distributions = ['norm', 'expon', 'gamma', 'lognorm', 'beta']\n",
    "\n",
    "# Fit distributions and calculate KS statistic\n",
    "results = []\n",
    "for dist_name in distributions:\n",
    "    dist = getattr(stats, dist_name)\n",
    "    params = dist.fit(purchase_dates)\n",
    "    ks_stat, p_value = stats.kstest(purchase_dates, dist_name, args=params)\n",
    "    results.append((dist_name, ks_stat, p_value))\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame(results, columns=['Distribution', 'KS Statistic', 'P-Value'])\n",
    "print(results_df)\n",
    "\n",
    "# Plot the best fitting distribution\n",
    "best_dist_name = results_df.sort_values('KS Statistic').iloc[0]['Distribution']\n",
    "best_dist = getattr(stats, best_dist_name)\n",
    "best_params = best_dist.fit(purchase_dates)\n",
    "\n",
    "# Plot histogram and fitted distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(purchase_dates, kde=False, bins=30, color='skyblue', stat='density')\n",
    "\n",
    "# Plot the PDF of the best fitting distribution\n",
    "x = np.linspace(min(purchase_dates), max(purchase_dates), 1000)\n",
    "pdf_fitted = best_dist.pdf(x, *best_params)\n",
    "plt.plot(x, pdf_fitted, 'r-', label=f'Best fit: {best_dist_name}')\n",
    "\n",
    "plt.xlabel('Purchase Date (ordinal)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Best Fitting Distribution for Purchase Dates')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_dates = hb_dataset['Arrival'].apply(lambda x: x.toordinal())\n",
    "\n",
    "# List of distributions to check\n",
    "distributions = ['norm', 'expon', 'gamma', 'lognorm', 'beta']\n",
    "\n",
    "# Fit distributions and calculate KS statistic\n",
    "results = []\n",
    "for dist_name in distributions:\n",
    "    dist = getattr(stats, dist_name)\n",
    "    params = dist.fit(arrival_dates)\n",
    "    ks_stat, p_value = stats.kstest(arrival_dates, dist_name, args=params)\n",
    "    results.append((dist_name, ks_stat, p_value))\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame(results, columns=['Distribution', 'KS Statistic', 'P-Value'])\n",
    "print(results_df)\n",
    "\n",
    "# Plot the best fitting distribution\n",
    "best_dist_name = results_df.sort_values('KS Statistic').iloc[0]['Distribution']\n",
    "best_dist = getattr(stats, best_dist_name)\n",
    "best_params = best_dist.fit(arrival_dates)\n",
    "\n",
    "# Plot histogram and fitted distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(arrival_dates, kde=False, bins=30, color='skyblue', stat='density')\n",
    "\n",
    "# Plot the PDF of the best fitting distribution\n",
    "x = np.linspace(min(arrival_dates), max(arrival_dates), 1000)\n",
    "pdf_fitted = best_dist.pdf(x, *best_params)\n",
    "plt.plot(x, pdf_fitted, 'r-', label=f'Best fit: {best_dist_name}')\n",
    "\n",
    "plt.xlabel('Arrival Date (ordinal)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Best Fitting Distribution for Arrival Dates')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which between our customers had most revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "revenue_per_hotel = hb_dataset.groupby(['HotelId', 'City'])['Total'].sum().reset_index()\n",
    "revenue_per_hotel.sort_values(['Total'], inplace=True, ascending=False)\n",
    "revenue_per_hotel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='HotelId', y='Total', data=revenue_per_hotel)\n",
    "plt.xlabel('Hotel ID')\n",
    "plt.ylabel('Total Revenue')\n",
    "plt.title('Total Revenue per Hotel (2020-2024)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see in the dataset the correlation between data, but for doing this and reaching the correlation matrix we need to reduce the \n",
    "features, distiguish between categorical and numerical and doing one shot encoding, removing redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = hb_dataset.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = hb_dataset.select_dtypes(include=['object']).columns\n",
    "# Drop unnecessary columns\n",
    "corr_df = hb_dataset.drop(columns=['Code', 'Arrival', 'Departure', 'PurchaseDate', 'LastModified'])\n",
    "# One-hot encoding of categorical columns using pd.get_dummies\n",
    "df_encoded = pd.get_dummies(corr_df, drop_first=True)\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_encoded.corr()\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected some things are evident:\n",
    "- Rome is the city with higher possible revenue having an high correlation with Price.\n",
    "- Purchase Date and Arrival Date are correlated.\n",
    "Less evident is the behaviour for Season and the cities:\n",
    "- Expected behaviour that Olbia is overcrowded in Summer, since it is in Sardinia. \n",
    "For our purpose, compute demandscore is enough since we select just Arrival and treat the dataset like a time series.\n",
    "Now we will focus in model selection based on Arrival since our goal is to compute the demand score per hotel.\n",
    "There are two algorithms:\n",
    "    - Prophet\n",
    "    -  SARIMAX\n",
    "\n",
    "We'll see which is the best one for this dataset and we compute the score but first we need to detect anomalies for time series. Before we need to see if data contains anomalies and treat them. We aggregate the data weekly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data to get weekly demand\n",
    "hb_dataset['Week'] = hb_dataset['Arrival'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weekly_demand = hb_dataset.groupby('Week').size().reset_index(name='Demand')\n",
    "weekly_demand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection.\n",
    "An anomaly in a time series refers to a data point or sequence of data points that significantly deviates from the expected patterns or trends typically observed in the time series data. These anomalies can appear as abrupt changes in values, an increase in NULL values, missing segments of data, or other irregular patterns that differ from normal fluctuations. In our"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection with ISOLATION FOREST\n",
    "\n",
    " -   Normalization of the time series\n",
    " -   STL decomposition of the time series to extract the residual\n",
    " -   Apply ISOLATION FOREST to the residual\n",
    " - Remove points not considered anomalous by the Isolation Forest\n",
    " - Apply DBSCAN to the points outside the confidence region to obtain clusters of points close to each other\n",
    " - Points that do not belong to any cluster are the anomalies\n",
    "\n",
    "The Isolation Forest is a completely different type of algorithm compared to ARIMA and PROPHET. \n",
    "In fact, it does not aim to find a fitting function, but directly seeks anomalous points based on the contamination parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplot statmodels numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal-Trend decomposition using LOESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Apply STL decomposition\n",
    "stl = STL(df['Value'], seasonal=13)\n",
    "result = stl.fit()\n",
    "\n",
    "# Extract the residual\n",
    "residual = result.resid\n",
    "\n",
    "# Plot the decomposition results\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposition results\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot residual component\n",
    "plt.figure()\n",
    "plt.plot(residual)\n",
    "plt.title(\"Residual Component\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest(contamination=0.05)  # Adjust contamination as needed\n",
    "df['anomaly_score'] = iso_forest.fit_predict(residual.values.reshape(-1, 1)]\n",
    "df['is_anomaly'] = df['anomaly_score'] == -1\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df['Value'], label='Time Series')\n",
    "plt.scatter(df.index[df['is_anomaly']], df['Value'][df['is_anomaly']], color='red', label='Anomalies')\n",
    "plt.title('Time Series with Anomalies Detected by Isolation Forest')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plot the residual with anomalies marked\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, residual, label='Residual')\n",
    "plt.scatter(df.index[df['is_anomaly']], residual[df['is_anomaly']], color='red', label='Anomalies')\n",
    "plt.title('Residual with Anomalies Detected by Isolation Forest')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\n",
    "Normalization can be useful, and even required in some machine learning algorithms when your time series data has input values with differing scales.It may be required for algorithms, like k-Nearest neighbors, which uses distance calculations and Linear Regression and Artificial Neural Networks that weight input values.\n",
    "Normalization requires that you know or are able to accurately estimate the minimum and maximum observable values. You may be able to estimate these values from your available data. If your time series is trending up or down, estimating these expected values may be difficult and normalization may not be the best method to use on your problem.\n",
    "\n",
    "A value is normalized as follows:\n",
    "y = (x - min) / (max - min)\n",
    "\n",
    "Where the minimum and maximum values pertain to the value x being normalized.\n",
    "\n",
    "For example, for the temperature data, we could guesstimate the min and max observable values as 30 and -10, which are greatly over and under-estimated. We can then normalize any value like 18.8 as follows:\n",
    "y = (x - min) / (max - min)\n",
    "y = (18.8 - -10) / (30 - -10)\n",
    "y = 28.8 / 40\n",
    "y = 0.72\n",
    "\n",
    "You can see that if an x value is provided that is outside the bounds of the minimum and maximum values, that the resulting value will not be in the range of 0 and 1. You could check for these observations prior to making predictions and either remove them from the dataset or limit them to the pre-defined maximum or minimum values.\n",
    "\n",
    "You can normalize your dataset using the scikit-learn object MinMaxScaler.\n",
    "\n",
    "Good practice usage with the MinMaxScaler and other rescaling techniques is as follows:\n",
    "\n",
    "    Fit the scaler using available training data. For normalization, this means the training data will be used to estimate the minimum and maximum observable values. This is done by calling the fit() function,\n",
    "    Apply the scale to training data. This means you can use the normalized data to train your model. This is done by calling the transform() function\n",
    "    Apply the scale to data going forward. This means you can prepare new data in the future on which you want to make predictions.\n",
    "\n",
    "If needed, the transform can be inverted. This is useful for converting predictions back into their original scale for reporting or plotting. This can be done by calling the inverse_transform() function.\n",
    "\n",
    "Below is an example of normalizing the Minimum Daily Temperatures dataset.\n",
    "\n",
    "The scaler requires data to be provided as a matrix of rows and columns. The loaded time series data is loaded as a Pandas Series. It must then be reshaped into a matrix of one column with 3,650 rows.\n",
    "\n",
    "The reshaped dataset is then used to fit the scaler, the dataset is normalized, then the normalization transform is inverted to show the original values again.\n",
    "# Normalize time series data\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load the dataset and print the first 5 rows\n",
    "series = read_csv('daily-minimum-temperatures-in-me.csv', header=0, index_col=0)\n",
    "print(series.head())\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "# train the normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "# normalize the dataset and print the first 5 rows\n",
    "normalized = scaler.transform(values)\n",
    "for i in range(5):\n",
    " print(normalized[i])\n",
    "# inverse transform and print the first 5 rows\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "for i in range(5):\n",
    " print(inversed[i])\n",
    "\n",
    "Running the example prints the first 5 rows from the loaded dataset, shows the same 5 values in their normalized form, then the values back in their original scale using the inverse transform.\n",
    "\n",
    "We can also see that the minimum and maximum values of the dataset are 0 and 26.3 respectively.\n",
    "Date\n",
    "1981-01-01 20.7\n",
    "1981-01-02 17.9\n",
    "1981-01-03 18.8\n",
    "1981-01-04 14.6\n",
    "1981-01-05 15.8\n",
    "Name: Temp, dtype: float64\n",
    "Min: 0.000000, Max: 26.300000\n",
    "[ 0.78707224]\n",
    "[ 0.68060837]\n",
    "[ 0.7148289]\n",
    "[ 0.55513308]\n",
    "[ 0.60076046]\n",
    "[ 20.7]\n",
    "[ 17.9]\n",
    "[ 18.8]\n",
    "[ 14.6]\n",
    "[ 15.8]\n",
    "\n",
    "There is another type of rescaling that is more robust to new values being outside the range of expected values; this is called Standardization. We will look at that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " STL uses LOESS (locally estimated scatterplot smoothing) to extract smooths estimates of the three components. The key inputs into STL are:\n",
    "\n",
    "    season - The length of the seasonal smoother. Must be odd.\n",
    "\n",
    "    trend - The length of the trend smoother, usually around 150% of season. Must be odd and larger than season.\n",
    "\n",
    "    low_pass - The length of the low-pass estimation window, usually the smallest odd number larger than the periodicity of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Computing STL and ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = STL(y, period=period, seasonal=seasonal)\n",
    "%timeit mod.fit()\n",
    "res = mod.fit()\n",
    "fig = res.plot(observed=False, resid=False)\n",
    "# Extract the residual\n",
    "residual = result.resid\n",
    "\n",
    "# Plot the decomposition results\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot residual component\n",
    "plt.figure()\n",
    "plt.plot(residual)\n",
    "plt.title(\"Residual Component\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Aggregate the data to get weekly demand\n",
    "hb_dataset['Week'] = hb_dataset['Arrival'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weekly_demand = hb_dataset.groupby('Week').size().reset_index(name='Demand')\n",
    "weekly_demand.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data for Prophet\n",
    "weekly_demand_prophet = weekly_demand.rename(columns={'Week': 'ds', 'Demand': 'y'})\n",
    "\n",
    "# Fit Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(weekly_demand_prophet)\n",
    "\n",
    "# Make a future dataframe for Prophet\n",
    "future_prophet = prophet_model.make_future_dataframe(periods=52, freq='W')\n",
    "forecast_prophet = prophet_model.predict(future_prophet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_demand_prophet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_prophet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model\n",
    "arima_model = SARIMAX(weekly_demand['Demand'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 52))\n",
    "arima_model_fit = arima_model.fit(disp=False)\n",
    "# Forecast using ARIMA\n",
    "forecast_arima = arima_model_fit.get_forecast(steps=52)\n",
    "forecast_arima_df = forecast_arima.summary_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the forecast data for comparison\n",
    "forecast_prophet = forecast_prophet[['ds', 'yhat']].set_index('ds')\n",
    "forecast_arima_df = forecast_arima_df[['mean']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance\n",
    "Better SARIMA. So we will use SARIMA for the compute of the score based on arrival. Let's motivate the process:\n",
    "- Mean Average Error (MSE): Tells us the average magnitude of the forecast errors. \n",
    "- Mean Square Error: Emphasizes larger errors more than MAE. \n",
    "- Root Mean Square Error: Provides an error measure in the same units as the demand. \n",
    "\n",
    "## Comparing Models\n",
    "- SARIMA shows an higher MAE than Prophet but perform better since MSE and RMSE are lower.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute evaluation metrics\n",
    "# For Prophet\n",
    "prophet_true = weekly_demand['Demand'].values[-52:]\n",
    "prophet_pred = forecast_prophet['yhat'].values[:52]\n",
    "prophet_mae = mean_absolute_error(prophet_true, prophet_pred)\n",
    "prophet_mse = mean_squared_error(prophet_true, prophet_pred)\n",
    "prophet_rmse = np.sqrt(prophet_mse)\n",
    "prophet_mape = mean_absolute_percentage_error(prophet_true, prophet_pred) \n",
    "# For ARIMA\n",
    "arima_true = weekly_demand['Demand'].values[-52:]\n",
    "arima_pred = forecast_arima_df['mean'].values[:52]\n",
    "arima_mae = mean_absolute_error(arima_true, arima_pred)\n",
    "arima_mse = mean_squared_error(arima_true, arima_pred)\n",
    "arima_rmse = np.sqrt(arima_mse)\n",
    "arima_mape = mean_absolute_percentage_error(arima_true, arume_pred)\n",
    "print(f'Arima MAPE: {arima_mape * 100:.2f}%')\n",
    "# Print evaluation metrics\n",
    "print(f\"Prophet MAE: {prophet_mae}, MSE: {prophet_mse}, RMSE: {prophet_rmse}\")\n",
    "print(f\"ARIMA MAE: {arima_mae}, MSE: {arima_mse}, RMSE: {arima_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Review Score</b> using BERT Sentiment Analysis over Tripadvisor Reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Hotel performance in terms of revenue depends stricly from online reputation (cit), so our goal in designing <b>HotelRank</p> algorithm is to analyze reviews about our customers hotel and provide an unique score to put a linear factor in HotelRank. We can name that score as <i>review score</i>.</p>\n",
    "<p><B>ReviewScore = Hotel_Rating - (0.5 * #number_negative review) + (0.25 * number of positive review)</B></p>\n",
    "<p>Here we emphasize the idea that is better not having negitive than positive reviews. To compute this formula we need we are in need to perform sentiment analysis over hotel reviews.</p><p>In case the <b>ReviewScore</b> is negative we assume that his weight to HotelRank is 0</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state-of-the-art sentiment analysis can be accomplished by fine-tuning pretrained BERT models with sentiment-analysis datasets. Fine-tuning is accomplished by further training a pretrained model for a limited number of epochs and with a reduced learning rate. We have collected the review using a scraper that we've coded in Go programming Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(samples):\n",
    "    return tokenizer(samples['Text'], truncation=True)\n",
    "\n",
    "tokenized_imdb = imdb.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the reviews are tokenized, they need to be converted from [Hugging Face datasets](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset) into [TensorFlow datasets](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) with Hugging Face’s [Dataset.to_tf_dataset](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.to_tf_dataset) method. The collating function passed to that method dynamically pads the sequences so they’re all the same length. You can also ask the tokenizer to do the padding, but padding performed that way is static and requires more memory:\n",
    "                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors='tf')\n",
    "\n",
    "train_data = tokenized_imdb['train'].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'label'],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "validation_data = tokenized_imdb['test'].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'label'],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you’re ready to fine-tune. Call `fit` on the model as usual, but set the `Adam` optimizer’s learning rate (the nominal amount that weights and biases are adjusted during backpropagation passes) to 0.00002, which is a fraction of the default learning rate of 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "model.compile(Adam(learning_rate=2e-5), metrics=['accuracy'])\n",
    "hist = model.fit(train_data, validation_data=validation_data, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "acc = hist.history['accuracy']\n",
    "val = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish up by defining an `analyze_text` function that returns a sentiment score and using it to score a positive review for sentiment. The model returns an object wrapping a tensor containing unnormalized sentiment scores (negative and positive), but you can use TensorFlow’s `softmax` function to normalize them to values from 0.0 to 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import panda as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "def analyze_text(text, tokenizer, model):\n",
    "    tokenized_text = tokenizer(text, padding=True, truncation=True, return_tensors='tf')\n",
    "    prediction = model(tokenized_text)\n",
    "    return tf.nn.softmax(prediction[0]).numpy()[0][1]\n",
    "\n",
    "review_data = glob.glob('review_data/*.csv')\n",
    "datasets = [pd.read_csv(filedata) for filedata in review_data]\n",
    "datasets[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancellation Score: Analysis on Cancellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
