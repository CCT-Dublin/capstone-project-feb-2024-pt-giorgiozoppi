{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>TrackML/HotelRank</b>: Elevating Revenue Performance Through Machine Learning and Deep Learning Techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revenue management is a very important to make profits in the hotel industry, three main factors play an important role to get it right:  \n",
    "    - Hotel room demand over time (demand forecast)\n",
    "    - Prediction of booking cancellations.\n",
    "    - Online hotel reputation.\n",
    "In this project we take in account each one thru a linear combination of different scores that represent each item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>DemandScore</b>: Demand Forecast over 12 months booking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective to section to concentrate ourselves to demand forecast with just Blastness dataset and nothing more:\n",
    "- We have to clean the data provided and see patterns.\n",
    "- Detect outliers in the demand\n",
    "- Compare SARIMAX and prophet neural network to see which fits better for the demandscore.\n",
    "- Create the demand score for each hotel using booking forecast in next temporal year frame.\n",
    "- We leave to future work any crossdata about the demand related to weather and external events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bamboolib\n",
      "  Downloading bamboolib-1.30.19-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: attrs>=20.3.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (23.1.0)\n",
      "Requirement already satisfied: cryptography>=2.6.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (42.0.5)\n",
      "Requirement already satisfied: ipywidgets<8.0.0,>=7.6.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (7.8.1)\n",
      "Requirement already satisfied: jedi<1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (0.18.1)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (1.5.3)\n",
      "Requirement already satisfied: packaging>=19.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (23.2)\n",
      "Requirement already satisfied: plotly<6.0.0,>=4.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (5.22.0)\n",
      "Requirement already satisfied: ppscore<2.0.0,>=1.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (1.3.0)\n",
      "Requirement already satisfied: psutil<6,>=5.4.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (5.9.0)\n",
      "Requirement already satisfied: pygments in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (2.15.1)\n",
      "Collecting ipyslickgrid==0.0.3 (from bamboolib)\n",
      "  Downloading ipyslickgrid-0.0.3.tar.gz (51.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 MB\u001b[0m \u001b[31m304.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (1.4.2)\n",
      "Requirement already satisfied: statsmodels<1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (0.14.2)\n",
      "Requirement already satisfied: toml>=0.10.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (0.10.2)\n",
      "Requirement already satisfied: xlrd>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bamboolib) (2.0.1)\n",
      "Requirement already satisfied: notebook>=4.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipyslickgrid==0.0.3->bamboolib) (7.0.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cryptography>=2.6.1->bamboolib) (1.16.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (3.6.6)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (8.25.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets<8.0.0,>=7.6.0->bamboolib) (1.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jedi<1.0.0->bamboolib) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas<2.0.0,>=1.1.0->bamboolib) (1.26.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from plotly<6.0.0,>=4.9.0->bamboolib) (8.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->bamboolib) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from statsmodels<1.0.0->bamboolib) (0.5.6)\n",
      "Requirement already satisfied: pycparser in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.6.1->bamboolib) (2.21)\n",
      "Requirement already satisfied: decorator in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (3.0.43)\n",
      "Requirement already satisfied: stack-data in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (4.8.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (6.4.1)\n",
      "Requirement already satisfied: six in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels<1.0.0->bamboolib) (1.16.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (7.10.0)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (5.9.2)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.14.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.4)\n",
      "Requirement already satisfied: ipykernel in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (6.28.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.32.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.5)\n",
      "Requirement already satisfied: executing in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=4.0.0->ipywidgets<8.0.0,>=7.6.0->bamboolib) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (3.10.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2024.8.30)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.6.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.6.0)\n",
      "Requirement already satisfied: webencodings in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (0.5.1)\n",
      "Requirement already satisfied: fqdn in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.1)\n",
      "Requirement already satisfied: uri-template in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (24.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (2.5)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.0.0->ipyslickgrid==0.0.3->bamboolib) (1.2.3)\n",
      "Downloading bamboolib-1.30.19-py3-none-any.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m366.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ipyslickgrid\n",
      "  Building wheel for ipyslickgrid (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipyslickgrid: filename=ipyslickgrid-0.0.3-py2.py3-none-any.whl size=1823264 sha256=4a661f1c68139fe9186c685247db0609ea8c7cf03722db691d4c402058373959\n",
      "  Stored in directory: /home/jozoppi/.cache/pip/wheels/f1/c1/e3/9a338a297f3f97ead51f9755162fe930007bd4b45f874d488e\n",
      "Successfully built ipyslickgrid\n",
      "Installing collected packages: ipyslickgrid, bamboolib\n",
      "Successfully installed bamboolib-1.30.19 ipyslickgrid-0.0.3\n",
      "Requirement already satisfied: pandas in /home/jozoppi/anaconda3/lib/python3.12/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/jozoppi/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: seaborn in /home/jozoppi/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Collecting matplot\n",
      "  Downloading matplot-0.1.9-py2.py3-none-any.whl.metadata (241 bytes)\n",
      "Requirement already satisfied: scikit-learn in /home/jozoppi/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyarrow in /home/jozoppi/anaconda3/lib/python3.12/site-packages (14.0.2)\n",
      "Collecting prophet\n",
      "  Downloading prophet-1.1.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: statsmodels in /home/jozoppi/anaconda3/lib/python3.12/site-packages (0.14.2)\n",
      "Collecting pycaret\n",
      "  Downloading pycaret-3.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from seaborn) (3.8.4)\n",
      "Collecting pyloco>=0.0.134 (from matplot)\n",
      "  Downloading pyloco-0.0.139-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Collecting cmdstanpy>=1.0.4 (from prophet)\n",
      "  Downloading cmdstanpy-1.2.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting holidays<1,>=0.25 (from prophet)\n",
      "  Downloading holidays-0.58-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prophet) (4.66.4)\n",
      "Collecting importlib-resources (from prophet)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (8.25.0)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (7.8.1)\n",
      "Requirement already satisfied: jinja2>=3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (3.1.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.11.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m789.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyod>=1.1.3 (from pycaret)\n",
      "  Downloading pyod-2.0.2.tar.gz (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.8/165.8 kB\u001b[0m \u001b[31m168.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: imbalanced-learn>=0.12.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.12.3)\n",
      "Collecting category-encoders>=2.4.0 (from pycaret)\n",
      "  Downloading category_encoders-2.6.4-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting lightgbm>=3.0.0 (from pycaret)\n",
      "  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numba>=0.55.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (0.59.1)\n",
      "Requirement already satisfied: requests>=2.27.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.32.2)\n",
      "Requirement already satisfied: psutil>=5.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (5.9.0)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (7.0.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (5.9.2)\n",
      "Requirement already satisfied: cloudpickle in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (2.2.1)\n",
      "Collecting deprecation>=2.1.0 (from pycaret)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from pycaret)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.7.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting scikit-plot>=0.3.7 (from pycaret)\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting yellowbrick>=1.4 (from pycaret)\n",
      "  Downloading yellowbrick-1.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: plotly>=5.14.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (5.22.0)\n",
      "Collecting kaleido>=0.2.1 (from pycaret)\n",
      "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Collecting schemdraw==0.15 (from pycaret)\n",
      "  Downloading schemdraw-0.15-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting plotly-resampler>=0.8.3.1 (from pycaret)\n",
      "  Downloading plotly_resampler-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sktime==0.26.0 (from pycaret)\n",
      "  Downloading sktime-0.26.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tbats>=1.1.3 (from pycaret)\n",
      "  Downloading tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pmdarima>=2.0.4 (from pycaret)\n",
      "  Downloading pmdarima-2.0.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: wurlitzer in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pycaret) (3.0.2)\n",
      "Collecting scikit-base<0.8.0 (from sktime==0.26.0->pycaret)\n",
      "  Downloading scikit_base-0.7.8-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: filelock in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (0.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Collecting stanio<2.0.0,>=0.4.0 (from cmdstanpy>=1.0.4->prophet)\n",
      "  Downloading stanio-0.5.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.22.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from importlib-metadata>=4.12.0->pycaret) (3.17.0)\n",
      "Requirement already satisfied: decorator in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipython>=5.5.0->pycaret) (4.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets>=7.6.5->pycaret) (0.2.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets>=7.6.5->pycaret) (3.6.6)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipywidgets>=7.6.5->pycaret) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: fastjsonschema in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbformat>=4.2.0->pycaret) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbformat>=4.2.0->pycaret) (4.19.2)\n",
      "Requirement already satisfied: jupyter-core in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from numba>=0.55.0->pycaret) (0.42.0)\n",
      "Requirement already satisfied: six in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from plotly>=5.14.0->pycaret) (8.2.2)\n",
      "Collecting dash>=2.9.0 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading dash-2.18.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting orjson<4.0.0,>=3.8.0 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading orjson-3.10.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m313.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tsdownsample>=0.1.3 (from plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading tsdownsample-0.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima>=2.0.4->pycaret)\n",
      "  Downloading Cython-3.0.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: urllib3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pmdarima>=2.0.4->pycaret) (2.2.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pmdarima>=2.0.4->pycaret) (69.5.1)\n",
      "Collecting ushlex (from pyloco>=0.0.134->matplot)\n",
      "  Downloading ushlex-0.99.1.tar.gz (4.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: websocket-client in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pyloco>=0.0.134->matplot) (1.8.0)\n",
      "Collecting twine (from pyloco>=0.0.134->matplot)\n",
      "  Downloading twine-5.1.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typing (from pyloco>=0.0.134->matplot)\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m725.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting SimpleWebSocketServer (from pyloco>=0.0.134->matplot)\n",
      "  Downloading SimpleWebSocketServer-0.1.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.27.1->pycaret) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.27.1->pycaret) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from requests>=2.27.1->pycaret) (2024.8.30)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
      "Collecting dash-html-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dash-table==5.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n",
      "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: retrying in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.10.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (7.0.8)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-core->nbformat>=4.2.0->pycaret) (3.10.0)\n",
      "Requirement already satisfied: executing in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=5.5.0->pycaret) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=5.5.0->pycaret) (0.2.2)\n",
      "Requirement already satisfied: pkginfo>=1.8.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (1.10.0)\n",
      "Collecting readme-renderer>=35.0 (from twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (1.0.0)\n",
      "Requirement already satisfied: keyring>=15.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (24.3.1)\n",
      "Collecting rfc3986>=1.4.0 (from twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from twine->pyloco>=0.0.134->matplot) (13.3.5)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.2)\n",
      "Requirement already satisfied: jaraco.classes in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (3.2.1)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (3.3.1)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (0.7.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (6.4.1)\n",
      "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting docutils>=0.21.2 (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot)\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (2.2.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (8.6.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (7.10.0)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.14.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.17.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.0.4)\n",
      "Requirement already satisfied: ipykernel in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (6.28.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.9.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (0.1.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (42.0.5)\n",
      "Requirement already satisfied: more-itertools in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jaraco.classes->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (10.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (1.16.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.6.7)\n",
      "Requirement already satisfied: webencodings in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (2.21)\n",
      "Requirement already satisfied: fqdn in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.1)\n",
      "Requirement already satisfied: uri-template in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (24.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (2.5)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/jozoppi/anaconda3/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets>=7.6.5->pycaret) (1.2.3)\n",
      "Downloading matplot-0.1.9-py2.py3-none-any.whl (5.0 kB)\n",
      "Downloading prophet-1.1.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/14.4 MB\u001b[0m \u001b[31m295.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading pycaret-3.3.2-py3-none-any.whl (486 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.1/486.1 kB\u001b[0m \u001b[31m326.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading schemdraw-0.15-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m227.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sktime-0.26.0-py3-none-any.whl (21.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m251.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m209.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m230.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hDownloading category_encoders-2.6.4-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m163.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cmdstanpy-1.2.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m455.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading holidays-0.58-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m296.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m230.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m206.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hDownloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m251.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m10.4/11.6 MB\u001b[0m \u001b[31m305.4 kB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m��━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m10.4/11.6 MB\u001b[0m \u001b[31m305.4 kB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/http/client.py\", line 479, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/socket.py\", line 708, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/ssl.py\", line 1252, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/ssl.py\", line 1104, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/cli/req_command.py\", line 245, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/commands/install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/operations/prepare.py\", line 552, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/operations/prepare.py\", line 467, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/network/download.py\", line 183, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(value)\n",
      "  File \"/home/jozoppi/anaconda3/lib/python3.12/site-packages/pip/_vendor/urllib3/response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\u001b[31m\n",
      "\u001b[0mTrying to install bamboolib nbextension...\n",
      "Could not install bamboolib Jupyter Notebook extension because Jupyter Notebook is not available\n"
     ]
    }
   ],
   "source": [
    "!pip install bamboolib\n",
    "!pip install pandas numpy seaborn matplot scikit-learn pyarrow prophet statsmodels pycaret datasets \n",
    "!python -m bamboolib install_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first action we load the csv provided by Blastness and we create a dataset with columns names in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4557/1839287804.py:18: DtypeWarning: Columns (23,53,62,68,70,81) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "/tmp/ipykernel_4557/1839287804.py:18: DtypeWarning: Columns (23,52,55,58,59,60,81,89,90,91) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "/tmp/ipykernel_4557/1839287804.py:18: DtypeWarning: Columns (23,49,55,59,81,87,90) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "/tmp/ipykernel_4557/1839287804.py:18: DtypeWarning: Columns (23,52,53,55,58,59,60,62,68,70,81,89,90,91) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BoookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19887PMCMTT6</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>23/10/2021</td>\n",
       "      <td>30/10/2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>31/05/2021</td>\n",
       "      <td>Website</td>\n",
       "      <td>31/05/2021 17:37:31</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19887FBFWGZ7</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>31/07/2021</td>\n",
       "      <td>06/08/2021</td>\n",
       "      <td>6</td>\n",
       "      <td>2894,25</td>\n",
       "      <td>08/07/2021</td>\n",
       "      <td>Website</td>\n",
       "      <td>08/07/2021 22:23:51</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19887JIZNTR8</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>23/10/2021</td>\n",
       "      <td>26/10/2021</td>\n",
       "      <td>3</td>\n",
       "      <td>2142,00</td>\n",
       "      <td>04/10/2021</td>\n",
       "      <td>Website</td>\n",
       "      <td>04/10/2021 21:24:49</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19887CNIHY10</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>23/11/2022</td>\n",
       "      <td>28/11/2022</td>\n",
       "      <td>5</td>\n",
       "      <td>3696,00</td>\n",
       "      <td>01/06/2022</td>\n",
       "      <td>Website</td>\n",
       "      <td>01/06/2022 10:46:15</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19887GOAMJ11</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>11/10/2022</td>\n",
       "      <td>15/10/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>4488,00</td>\n",
       "      <td>26/06/2022</td>\n",
       "      <td>Website</td>\n",
       "      <td>26/06/2022 04:14:05</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Code      Status BookingChannel     Arrival   Departure  Nights  \\\n",
       "0  19887PMCMTT6  Cancellata           Sito  23/10/2021  30/10/2021       0   \n",
       "1  19887FBFWGZ7  Confermata           Sito  31/07/2021  06/08/2021       6   \n",
       "2  19887JIZNTR8  Confermata           Sito  23/10/2021  26/10/2021       3   \n",
       "3  19887CNIHY10  Confermata           Sito  23/11/2022  28/11/2022       5   \n",
       "4  19887GOAMJ11  Confermata           Sito  11/10/2022  15/10/2022       4   \n",
       "\n",
       "     Total PurchaseDate BoookingDevice         LastModified HotelId  \n",
       "0     0,00   31/05/2021        Website  31/05/2021 17:37:31     010  \n",
       "1  2894,25   08/07/2021        Website  08/07/2021 22:23:51     010  \n",
       "2  2142,00   04/10/2021        Website  04/10/2021 21:24:49     010  \n",
       "3  3696,00   01/06/2022        Website  01/06/2022 10:46:15     010  \n",
       "4  4488,00   26/06/2022        Website  26/06/2022 04:14:05     010  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "filelist = glob.glob('./hoteldataset/*.csv')\n",
    "hotelsbookings = []\n",
    "column_mapping = {\n",
    "    'Codice': 'Code',\n",
    "    'Status': 'Status',\n",
    "    'Canale': 'BookingChannel',\n",
    "    'Arrivo': 'Arrival',\n",
    "    'Partenza': 'Departure',\n",
    "    'Notti': 'Nights',\n",
    "    'Totale': 'Total',\n",
    "    'Data acquisto': 'PurchaseDate',\n",
    "    'Dispositivo': 'BoookingDevice',\n",
    "    'Data Ultima Modifica/Cancellazione': 'LastModified'\n",
    "}\n",
    "for idx,f in enumerate(filelist):\n",
    "    df = pd.read_csv(f)\n",
    "    select_columns = list(column_mapping.keys())\n",
    "    current_df = df[select_columns]\n",
    "    remap = current_df.rename(columns=column_mapping)\n",
    "    hotel_id = \"\"\n",
    "    if idx < 9:\n",
    "        hotel_id=f'00{idx+1}'\n",
    "    else:\n",
    "        hotel_id=f'0{idx+1}'\n",
    "\n",
    "    remap['HotelId'] = hotel_id\n",
    "    hotelsbookings.append(remap)\n",
    "hotelsbookings[9].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge all hotels in a single dataframe and save to disk. We note that we need to divide cancelled and confirmed booking. Later since we want do forecast on the confirmed.\n",
    "- Also we need to categorize the origin\n",
    "- remove the booking device.\n",
    "\n",
    "First we merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "                         Code      Status BookingChannel     Arrival  \\\n",
      "0       1400576136/1204413850  Cancellata    Booking.com  22/07/2017   \n",
      "1       1240874198/1204820657  Cancellata    Booking.com  15/07/2017   \n",
      "2       1656344835/1204828455  Cancellata    Booking.com  22/07/2017   \n",
      "3       1656344835/1204828455  Cancellata    Booking.com  22/07/2017   \n",
      "4       1656344835/1204828455  Cancellata    Booking.com  22/07/2017   \n",
      "...                       ...         ...            ...         ...   \n",
      "151852           19887FIHJR22  Confermata           Sito  19/10/2023   \n",
      "151853           19887DOSJP23  Confermata           Sito  10/06/2023   \n",
      "151854           19887KTDJJ24  Confermata           Sito  18/07/2023   \n",
      "151855           19887LNQHJ25  Confermata           Sito  24/04/2023   \n",
      "151856           19887IENNC26  Confermata           Sito  18/09/2023   \n",
      "\n",
      "         Departure  Nights    Total PurchaseDate BoookingDevice  \\\n",
      "0       29/07/2017       0     0,00   01/01/2017            NaN   \n",
      "1       02/08/2017       0     0,00   01/01/2017            NaN   \n",
      "2       09/08/2017       0     0,00   01/01/2017            NaN   \n",
      "3       09/08/2017       0     0,00   01/01/2017            NaN   \n",
      "4       09/08/2017       0     0,00   01/01/2017            NaN   \n",
      "...            ...     ...      ...          ...            ...   \n",
      "151852  22/10/2023       3  3080,00   11/03/2023        Website   \n",
      "151853  12/06/2023       2  2112,00   17/03/2023        Website   \n",
      "151854  20/07/2023       2  2112,00   02/04/2023         Mobile   \n",
      "151855  27/04/2023       3  2640,00   08/04/2023        Website   \n",
      "151856  21/09/2023       3  3168,00   03/06/2023        Website   \n",
      "\n",
      "               LastModified HotelId  \n",
      "0       01/01/2017 15:27:39     001  \n",
      "1       01/01/2017 23:13:49     001  \n",
      "2       11/01/2017 21:59:16     001  \n",
      "3       10/01/2017 22:10:56     001  \n",
      "4       11/01/2017 21:59:16     001  \n",
      "...                     ...     ...  \n",
      "151852  11/03/2023 10:15:06     010  \n",
      "151853  17/03/2023 17:33:23     010  \n",
      "151854  02/04/2023 09:55:59     010  \n",
      "151855  08/04/2023 20:06:59     010  \n",
      "151856  03/06/2023 12:55:03     010  \n",
      "\n",
      "[151857 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge DataFrames\n",
    "merged_df = pd.concat(hotelsbookings, ignore_index=True)\n",
    "# Display the merged DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've seen a lot of not known or bad data. Just clean it. We want order by date, in descending mode and take only the last 2 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BoookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1400576136/1204413850</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>22/07/2017</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2017 15:27:39</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1240874198/1204820657</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>15/07/2017</td>\n",
       "      <td>02/08/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2017 23:13:49</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656344835/1204828455</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>22/07/2017</td>\n",
       "      <td>09/08/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/01/2017 21:59:16</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1656344835/1204828455</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>22/07/2017</td>\n",
       "      <td>09/08/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/01/2017 22:10:56</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1656344835/1204828455</td>\n",
       "      <td>Cancellata</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>22/07/2017</td>\n",
       "      <td>09/08/2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00</td>\n",
       "      <td>01/01/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/01/2017 21:59:16</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Code      Status BookingChannel     Arrival   Departure  \\\n",
       "0  1400576136/1204413850  Cancellata    Booking.com  22/07/2017  29/07/2017   \n",
       "1  1240874198/1204820657  Cancellata    Booking.com  15/07/2017  02/08/2017   \n",
       "2  1656344835/1204828455  Cancellata    Booking.com  22/07/2017  09/08/2017   \n",
       "3  1656344835/1204828455  Cancellata    Booking.com  22/07/2017  09/08/2017   \n",
       "4  1656344835/1204828455  Cancellata    Booking.com  22/07/2017  09/08/2017   \n",
       "\n",
       "   Nights Total PurchaseDate BoookingDevice         LastModified HotelId  \n",
       "0       0  0,00   01/01/2017            NaN  01/01/2017 15:27:39     001  \n",
       "1       0  0,00   01/01/2017            NaN  01/01/2017 23:13:49     001  \n",
       "2       0  0,00   01/01/2017            NaN  11/01/2017 21:59:16     001  \n",
       "3       0  0,00   01/01/2017            NaN  10/01/2017 22:10:56     001  \n",
       "4       0  0,00   01/01/2017            NaN  11/01/2017 21:59:16     001  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4557/459522789.py:1: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  merged_df['Arrival'] = pd.to_datetime(merged_df['Arrival'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Status</th>\n",
       "      <th>BookingChannel</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Nights</th>\n",
       "      <th>Total</th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>BoookingDevice</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>HotelId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151852</th>\n",
       "      <td>19887FIHJR22</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>22/10/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3080,00</td>\n",
       "      <td>11/03/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>11/03/2023 10:15:06</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151853</th>\n",
       "      <td>19887DOSJP23</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>12/06/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>2112,00</td>\n",
       "      <td>17/03/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>17/03/2023 17:33:23</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151849</th>\n",
       "      <td>19887VFAUN19</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>28/09/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>1760,00</td>\n",
       "      <td>02/02/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>02/02/2023 16:43:04</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151856</th>\n",
       "      <td>19887IENNC26</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-09-18</td>\n",
       "      <td>21/09/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>3168,00</td>\n",
       "      <td>03/06/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>03/06/2023 12:55:03</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151850</th>\n",
       "      <td>19887VNOHO20</td>\n",
       "      <td>Confermata</td>\n",
       "      <td>Sito</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>27/08/2023</td>\n",
       "      <td>2</td>\n",
       "      <td>1496,00</td>\n",
       "      <td>09/03/2023</td>\n",
       "      <td>Website</td>\n",
       "      <td>09/03/2023 20:00:03</td>\n",
       "      <td>010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Code      Status BookingChannel    Arrival   Departure  \\\n",
       "151852  19887FIHJR22  Confermata           Sito 2023-10-19  22/10/2023   \n",
       "151853  19887DOSJP23  Confermata           Sito 2023-10-06  12/06/2023   \n",
       "151849  19887VFAUN19  Confermata           Sito 2023-09-26  28/09/2023   \n",
       "151856  19887IENNC26  Confermata           Sito 2023-09-18  21/09/2023   \n",
       "151850  19887VNOHO20  Confermata           Sito 2023-08-25  27/08/2023   \n",
       "\n",
       "        Nights    Total PurchaseDate BoookingDevice         LastModified  \\\n",
       "151852       3  3080,00   11/03/2023        Website  11/03/2023 10:15:06   \n",
       "151853       2  2112,00   17/03/2023        Website  17/03/2023 17:33:23   \n",
       "151849       2  1760,00   02/02/2023        Website  02/02/2023 16:43:04   \n",
       "151856       3  3168,00   03/06/2023        Website  03/06/2023 12:55:03   \n",
       "151850       2  1496,00   09/03/2023        Website  09/03/2023 20:00:03   \n",
       "\n",
       "       HotelId  \n",
       "151852     010  \n",
       "151853     010  \n",
       "151849     010  \n",
       "151856     010  \n",
       "151850     010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Arrival'] = pd.to_datetime(merged_df['Arrival'])\n",
    "# Sorting by 'Arrival' column in descending order\n",
    "sorted_bookings_df = merged_df.sort_values(by='Arrival', ascending=False)\n",
    "# Filtering for HotelId '001'\n",
    "filtered_df = sorted_bookings_df.loc[sorted_bookings_df['HotelId'] == '010']\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I convert datates to timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN in 'Arrival': 0\n",
      "Rows with NaN in 'Departure': 0\n"
     ]
    }
   ],
   "source": [
    "# Filtering for HotelId '001'\n",
    "nan_rows = sorted_bookings_df[sorted_bookings_df['Arrival'].isna()]\n",
    "print(\"Rows with NaN in 'Arrival':\", len(nan_rows))\n",
    "nan_rows = sorted_bookings_df[sorted_bookings_df['Departure'].isna()]\n",
    "print(\"Rows with NaN in 'Departure':\", len(nan_rows))\n",
    "# conversion in datetime\n",
    "sorted_bookings_df['Arrival'] = pd.to_datetime(sorted_bookings_df['Arrival'], errors='coerce', dayfirst=True)\n",
    "sorted_bookings_df['Departure'] = pd.to_datetime(sorted_bookings_df['Departure'], errors='coerce', dayfirst=True)\n",
    "sorted_bookings_df['LastModified'] = pd.to_datetime(sorted_bookings_df['LastModified'], errors='coerce', dayfirst=True)\n",
    "sorted_bookings_df['PurchaseDate'] = pd.to_datetime(sorted_bookings_df['PurchaseDate'], errors='coerce', dayfirst=True)\n",
    "# we want to make sure that are numerical data\n",
    "sorted_bookings_df['Total'] = sorted_bookings_df['Total'].str.replace(',', '.').astype(float)\n",
    "sorted_bookings_df['Total'] = pd.to_numeric(sorted_bookings_df['Total'])\n",
    "sorted_bookings_df['Nights'] = pd.to_numeric(sorted_bookings_df['Nights'])\n",
    "# add timestamp\n",
    "sorted_bookings_df['Arrival_Timestamp'] = sorted_bookings_df['Arrival'].astype('int64')\n",
    "sorted_bookings_df['Departure_Timestamp'] = sorted_bookings_df['Departure'].astype('int64')\n",
    "sorted_bookings_df['LastModified_Timestamp'] = pd.to_datetime(sorted_bookings_df['LastModified'], errors='coerce')\n",
    "sorted_bookings_df['Purchase_Timestamp'] = sorted_bookings_df['PurchaseDate'].astype('int64')\n",
    "sorted_bookings_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to add the city to he dataset the client has provided the following mapping:\n",
    "```\n",
    "hotel_to_city = {\n",
    "    '001': \"Rome, Italu\",\n",
    "    '002': \"Naples, Italy\",\n",
    "    '003': \"Florence, Italy\",\n",
    "    '004': \"Florence, Italy\",\n",
    "    '005': \"Naples, Italy\",\n",
    "    '006': \"Brindisi, Italy\",\n",
    "    '007': \"Latina, Italy\",\n",
    "    '008': \"Olbia, Sardinia, Italy\",\n",
    "    '009': \"Chamonix-Mont-Blanc, France\",\n",
    "    '010': \"Rome, Italy\",\n",
    "}\n",
    "```\n",
    "So we can have a complete a dataset to correlate in future with events, weather and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_to_city = {\n",
    "    '001': \"Rome\",\n",
    "    '002': \"Naples\",\n",
    "    '003': \"Florence\",\n",
    "    '004': \"Florence\",\n",
    "    '005': \"Naples\",\n",
    "    '006': \"Brindisi\",\n",
    "    '007': \"Latina\",\n",
    "    '008': \"Olbia\",\n",
    "    '009': \"Chamonix-Mont-Blanc\",\n",
    "    '010': \"Rome\",\n",
    "}\n",
    "\n",
    "# Function to get the city name based on HotelId\n",
    "def get_city(hotel_id):\n",
    "    return coordinate_to_city.get(hotel_id, \"Unknown\")\n",
    "\n",
    "# Add the City column based on the HotelId\n",
    "sorted_bookings_df['City'] = sorted_bookings_df['HotelId'].apply(get_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want also add the season because we know from the domain the booking changes of season and when the booking device is not known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we clean unknown\n",
    "sorted_bookings_df['BoookingDevice'].fillna('Unknown', inplace=True)\n",
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "sorted_bookings_df['Season'] = sorted_bookings_df['Arrival'].apply(get_season)\n",
    "sorted_bookings_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before going further and doing descriptive statistics we neeed to know is there are still NaN. It is ok we store for future purposes the dataset in parquet file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any row in any column is NaN\n",
    "has_nan = sorted_bookings_df.isna().any().any()\n",
    "print(f\"Does the DataFrame contain any NaN values? {has_nan}\")\n",
    "# Display rows with any NaN values\n",
    "rows_with_nan = sorted_bookings_df[sorted_bookings_df.isna().any(axis=1)]\n",
    "print(\"Rows with NaN values:\")\n",
    "rows_with_nan.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. We've seen that the booking channel can be a valid string or Unknown. The other thing that we want is to the hotel booking for a fixed period from 2024 to 2022. After this we can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_bookings_df['BookingChannel'] = sorted_bookings_df['BookingChannel'].fillna('Unknown')\n",
    "sorted_bookings_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to restrict the timing interval between 2020 and 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-01-01'\n",
    "end_date = '2024-02-28'\n",
    "sorted_bookings_df.head()\n",
    "datetime_columns = ['Arrival', 'Departure', 'PurchaseDate', 'LastModified']\n",
    "for col in datetime_columns:\n",
    "    sorted_bookings_df[col] = pd.to_datetime(sorted_bookings_df[col])\n",
    "hb_dataset = sorted_bookings_df[(sorted_bookings_df['Arrival'] >= start_date) & (sorted_bookings_df['Arrival'] <= end_date)] \n",
    "# Check if any row in any column is NaN\n",
    "has_nan = hb_dataset.isna().any().any()\n",
    "print(f\"Does the DataFrame contain any NaN values? {has_nan}\")\n",
    "if has_nan:\n",
    "# Display rows with any NaN values\n",
    "    rows_with_nan = hb_dataset[hb_dataset.isna().any(axis=1)]\n",
    "    print(\"Rows with NaN values:\")\n",
    "    rows_with_nan.head()\n",
    "else:\n",
    "    print('The dataset is ready some descriptivre statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to a Parquet file\n",
    "parquet_file = 'filtered_data.parquet'\n",
    "hb_dataset.to_parquet(parquet_file)\n",
    "print(f\"Filtered DataFrame saved to {parquet_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection with ISOLATION FOREST\n",
    "\n",
    " -   Normalization of the time series\n",
    " -   STL decomposition of the time series to extract the residual\n",
    " -   Apply ISOLATION FOREST to the residual\n",
    " - Remove points not considered anomalous by the Isolation Forest\n",
    " - Apply DBSCAN to the points outside the confidence region to obtain clusters of points close to each other\n",
    " - Points that do not belong to any cluster are the anomalies\n",
    "\n",
    "The Isolation Forest is a completely different type of algorithm compared to ARIMA and PROPHET. \n",
    "In fact, it does not aim to find a fitting function, but directly seeks anomalous points based on the contamination parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seasonal-Trend decomposition using LOESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplot statmodels numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Example: Create a sample time series\n",
    "np.random.seed(10)\n",
    "time = pd.date_range('2020-01-01', periods=100, freq='D')\n",
    "data = 10 + np.sin(2 * np.pi * time.dayofyear / 365) + np.random.randn(100) * 0.5\n",
    "df = pd.DataFrame({'Date': time, 'Value': data}).set_index('Date')\n",
    "\n",
    "# Apply STL decomposition\n",
    "stl = STL(df['Value'], seasonal=13)\n",
    "result = stl.fit()\n",
    "\n",
    "# Extract the residual\n",
    "residual = result.resid\n",
    "\n",
    "# Plot the decomposition results\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decomposition results\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot residual component\n",
    "plt.figure()\n",
    "plt.plot(residual)\n",
    "plt.title(\"Residual Component\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Descriptive statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numeric columns only\n",
    "descriptive_stats = hb_dataset.describe()\n",
    "print(\"\\nDescriptive Statistics for numeric columns in the filtered DataFrame:\")\n",
    "print(descriptive_stats)\n",
    "descriptive_stats_all = hb_dataset.describe(include='all')\n",
    "print(\"\\nDescriptive Statistics for all columns in the filtered DataFrame:\")\n",
    "print(descriptive_stats_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that:\n",
    "- We've 39375 booking in the period.\n",
    "- The average staying is 1.6 days for each booking.\n",
    "- The medium booking revenue is 370 euros.\n",
    "That's not enough, we want to know:\n",
    "- How frequent is a booking?\n",
    "- Which between our customers how had most revenue?\n",
    "- Which has most room booked and and in which city?\n",
    "- Which is the season in which we've most rooom booked? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-01-01'\n",
    "end_date = '2024-12-31'\n",
    "filtered_df = hb_dataset[(hb_dataset['PurchaseDate'] >= start_date) & (hb_dataset['PurchaseDate'] <= end_date)]\n",
    "\n",
    "# Plot the distribution of purchase dates using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(filtered_df['PurchaseDate'], kde=True, bins=30)\n",
    "plt.xlabel('Purchase Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Purchase Dates (2020-2024)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(filtered_df['Arrival'], kde=True, bins=30)\n",
    "plt.xlabel('Arrival Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Arrival Dates (2020-2024)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sense. Most booking are at the beginning of the year and just before summer. Italians tends to go in vacation on August so in July the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'PurchaseDate' to ordinal for fitting distributions\n",
    "purchase_dates = hb_dataset['PurchaseDate'].apply(lambda x: x.toordinal())\n",
    "\n",
    "# List of distributions to check\n",
    "distributions = ['norm', 'expon', 'gamma', 'lognorm', 'beta']\n",
    "\n",
    "# Fit distributions and calculate KS statistic\n",
    "results = []\n",
    "for dist_name in distributions:\n",
    "    dist = getattr(stats, dist_name)\n",
    "    params = dist.fit(purchase_dates)\n",
    "    ks_stat, p_value = stats.kstest(purchase_dates, dist_name, args=params)\n",
    "    results.append((dist_name, ks_stat, p_value))\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame(results, columns=['Distribution', 'KS Statistic', 'P-Value'])\n",
    "print(results_df)\n",
    "\n",
    "# Plot the best fitting distribution\n",
    "best_dist_name = results_df.sort_values('KS Statistic').iloc[0]['Distribution']\n",
    "best_dist = getattr(stats, best_dist_name)\n",
    "best_params = best_dist.fit(purchase_dates)\n",
    "\n",
    "# Plot histogram and fitted distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(purchase_dates, kde=False, bins=30, color='skyblue', stat='density')\n",
    "\n",
    "# Plot the PDF of the best fitting distribution\n",
    "x = np.linspace(min(purchase_dates), max(purchase_dates), 1000)\n",
    "pdf_fitted = best_dist.pdf(x, *best_params)\n",
    "plt.plot(x, pdf_fitted, 'r-', label=f'Best fit: {best_dist_name}')\n",
    "\n",
    "plt.xlabel('Purchase Date (ordinal)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Best Fitting Distribution for Purchase Dates')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_dates = hb_dataset['Arrival'].apply(lambda x: x.toordinal())\n",
    "\n",
    "# List of distributions to check\n",
    "distributions = ['norm', 'expon', 'gamma', 'lognorm', 'beta']\n",
    "\n",
    "# Fit distributions and calculate KS statistic\n",
    "results = []\n",
    "for dist_name in distributions:\n",
    "    dist = getattr(stats, dist_name)\n",
    "    params = dist.fit(arrival_dates)\n",
    "    ks_stat, p_value = stats.kstest(arrival_dates, dist_name, args=params)\n",
    "    results.append((dist_name, ks_stat, p_value))\n",
    "\n",
    "# Print results\n",
    "results_df = pd.DataFrame(results, columns=['Distribution', 'KS Statistic', 'P-Value'])\n",
    "print(results_df)\n",
    "\n",
    "# Plot the best fitting distribution\n",
    "best_dist_name = results_df.sort_values('KS Statistic').iloc[0]['Distribution']\n",
    "best_dist = getattr(stats, best_dist_name)\n",
    "best_params = best_dist.fit(arrival_dates)\n",
    "\n",
    "# Plot histogram and fitted distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(arrival_dates, kde=False, bins=30, color='skyblue', stat='density')\n",
    "\n",
    "# Plot the PDF of the best fitting distribution\n",
    "x = np.linspace(min(arrival_dates), max(arrival_dates), 1000)\n",
    "pdf_fitted = best_dist.pdf(x, *best_params)\n",
    "plt.plot(x, pdf_fitted, 'r-', label=f'Best fit: {best_dist_name}')\n",
    "\n",
    "plt.xlabel('Arrival Date (ordinal)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Best Fitting Distribution for Arrival Dates')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which between our customers had most revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "revenue_per_hotel = hb_dataset.groupby(['HotelId', 'City'])['Total'].sum().reset_index()\n",
    "revenue_per_hotel.sort_values(['Total'], inplace=True, ascending=False)\n",
    "revenue_per_hotel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='HotelId', y='Total', data=revenue_per_hotel)\n",
    "plt.xlabel('Hotel ID')\n",
    "plt.ylabel('Total Revenue')\n",
    "plt.title('Total Revenue per Hotel (2020-2024)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see in the dataset the correlation between data, but for doing this and reaching the correlation matrix we need to reduce the \n",
    "features, distiguish between categorical and numerical and doing one shot encoding, removing redundant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = hb_dataset.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = hb_dataset.select_dtypes(include=['object']).columns\n",
    "# Drop unnecessary columns\n",
    "corr_df = hb_dataset.drop(columns=['Code', 'Arrival', 'Departure', 'PurchaseDate', 'LastModified'])\n",
    "# One-hot encoding of categorical columns using pd.get_dummies\n",
    "df_encoded = pd.get_dummies(corr_df, drop_first=True)\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_encoded.corr()\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected some things are evident:\n",
    "- Rome is the city with higher possible revenue having an high correlation with Price.\n",
    "- Purchase Date and Arrival Date are correlated.\n",
    "Less evident is the behaviour for Season and the cities:\n",
    "- Expected behaviour that Olbia is overcrowded in Summer, since it is in Sardinia. Probabally another cleaning iteration is needed here.\n",
    "For our purpose, compute demandscore is enough since we select just Arrival and treat the dataset like a time series.\n",
    "Now we will focus in model selection based on Arrival since our goal is to compute the demand score per hotel.\n",
    "There are two algorithms:\n",
    "    - Prophet\n",
    "    - SARIMAX\n",
    "\n",
    "We'll see which is the best one for this dataset and we compute the score but first we need to detect anomalies for time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anomalies detection f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anomaly detection with ISOLATION FOREST\n",
    "\n",
    " -   Normalization of the time series\n",
    " -   STL decomposition of the time series to extract the residual\n",
    " -   Apply ISOLATION FOREST to the residual\n",
    " - Remove points not considered anomalous by the Isolation Forest\n",
    " - Apply DBSCAN to the points outside the confidence region to obtain clusters of points close to each other\n",
    " - Points that do not belong to any cluster are the anomalies\n",
    "\n",
    "The Isolation Forest is a completely different type of algorithm compared to ARIMA and PROPHET. \n",
    "In fact, it does not aim to find a fitting function, but directly seeks anomalous points based on the contamination parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\n",
    "Normalization can be useful, and even required in some machine learning algorithms when your time series data has input values with differing scales.It may be required for algorithms, like k-Nearest neighbors, which uses distance calculations and Linear Regression and Artificial Neural Networks that weight input values.\n",
    "Normalization requires that you know or are able to accurately estimate the minimum and maximum observable values. You may be able to estimate these values from your available data. If your time series is trending up or down, estimating these expected values may be difficult and normalization may not be the best method to use on your problem.\n",
    "\n",
    "A value is normalized as follows:\n",
    "y = (x - min) / (max - min)\n",
    "\n",
    "Where the minimum and maximum values pertain to the value x being normalized.\n",
    "\n",
    "For example, for the temperature data, we could guesstimate the min and max observable values as 30 and -10, which are greatly over and under-estimated. We can then normalize any value like 18.8 as follows:\n",
    "y = (x - min) / (max - min)\n",
    "y = (18.8 - -10) / (30 - -10)\n",
    "y = 28.8 / 40\n",
    "y = 0.72\n",
    "\n",
    "You can see that if an x value is provided that is outside the bounds of the minimum and maximum values, that the resulting value will not be in the range of 0 and 1. You could check for these observations prior to making predictions and either remove them from the dataset or limit them to the pre-defined maximum or minimum values.\n",
    "\n",
    "You can normalize your dataset using the scikit-learn object MinMaxScaler.\n",
    "\n",
    "Good practice usage with the MinMaxScaler and other rescaling techniques is as follows:\n",
    "\n",
    "    Fit the scaler using available training data. For normalization, this means the training data will be used to estimate the minimum and maximum observable values. This is done by calling the fit() function,\n",
    "    Apply the scale to training data. This means you can use the normalized data to train your model. This is done by calling the transform() function\n",
    "    Apply the scale to data going forward. This means you can prepare new data in the future on which you want to make predictions.\n",
    "\n",
    "If needed, the transform can be inverted. This is useful for converting predictions back into their original scale for reporting or plotting. This can be done by calling the inverse_transform() function.\n",
    "\n",
    "Below is an example of normalizing the Minimum Daily Temperatures dataset.\n",
    "\n",
    "The scaler requires data to be provided as a matrix of rows and columns. The loaded time series data is loaded as a Pandas Series. It must then be reshaped into a matrix of one column with 3,650 rows.\n",
    "\n",
    "The reshaped dataset is then used to fit the scaler, the dataset is normalized, then the normalization transform is inverted to show the original values again.\n",
    "# Normalize time series data\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load the dataset and print the first 5 rows\n",
    "series = read_csv('daily-minimum-temperatures-in-me.csv', header=0, index_col=0)\n",
    "print(series.head())\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "# train the normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "# normalize the dataset and print the first 5 rows\n",
    "normalized = scaler.transform(values)\n",
    "for i in range(5):\n",
    " print(normalized[i])\n",
    "# inverse transform and print the first 5 rows\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "for i in range(5):\n",
    " print(inversed[i])\n",
    "\n",
    "Running the example prints the first 5 rows from the loaded dataset, shows the same 5 values in their normalized form, then the values back in their original scale using the inverse transform.\n",
    "\n",
    "We can also see that the minimum and maximum values of the dataset are 0 and 26.3 respectively.\n",
    "Date\n",
    "1981-01-01 20.7\n",
    "1981-01-02 17.9\n",
    "1981-01-03 18.8\n",
    "1981-01-04 14.6\n",
    "1981-01-05 15.8\n",
    "Name: Temp, dtype: float64\n",
    "Min: 0.000000, Max: 26.300000\n",
    "[ 0.78707224]\n",
    "[ 0.68060837]\n",
    "[ 0.7148289]\n",
    "[ 0.55513308]\n",
    "[ 0.60076046]\n",
    "[ 20.7]\n",
    "[ 17.9]\n",
    "[ 18.8]\n",
    "[ 14.6]\n",
    "[ 15.8]\n",
    "\n",
    "There is another type of rescaling that is more robust to new values being outside the range of expected values; this is called Standardization. We will look at that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " STL uses LOESS (locally estimated scatterplot smoothing) to extract smooths estimates of the three components. The key inputs into STL are:\n",
    "\n",
    "    season - The length of the seasonal smoother. Must be odd.\n",
    "\n",
    "    trend - The length of the trend smoother, usually around 150% of season. Must be odd and larger than season.\n",
    "\n",
    "    low_pass - The length of the low-pass estimation window, usually the smallest odd number larger than the periodicity of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Computing STL and ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = STL(y, period=period, seasonal=seasonal)\n",
    "%timeit mod.fit()\n",
    "res = mod.fit()\n",
    "fig = res.plot(observed=False, resid=False)\n",
    "# Extract the residual\n",
    "residual = result.resid\n",
    "\n",
    "# Plot the decomposition results\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot residual component\n",
    "plt.figure()\n",
    "plt.plot(residual)\n",
    "plt.title(\"Residual Component\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Aggregate the data to get weekly demand\n",
    "hb_dataset['Week'] = hb_dataset['Arrival'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weekly_demand = hb_dataset.groupby('Week').size().reset_index(name='Demand')\n",
    "weekly_demand.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data for Prophet\n",
    "weekly_demand_prophet = weekly_demand.rename(columns={'Week': 'ds', 'Demand': 'y'})\n",
    "\n",
    "# Fit Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(weekly_demand_prophet)\n",
    "\n",
    "# Make a future dataframe for Prophet\n",
    "future_prophet = prophet_model.make_future_dataframe(periods=52, freq='W')\n",
    "forecast_prophet = prophet_model.predict(future_prophet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_demand_prophet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_prophet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model\n",
    "arima_model = SARIMAX(weekly_demand['Demand'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 52))\n",
    "arima_model_fit = arima_model.fit(disp=False)\n",
    "# Forecast using ARIMA\n",
    "forecast_arima = arima_model_fit.get_forecast(steps=52)\n",
    "forecast_arima_df = forecast_arima.summary_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the forecast data for comparison\n",
    "forecast_prophet = forecast_prophet[['ds', 'yhat']].set_index('ds')\n",
    "forecast_arima_df = forecast_arima_df[['mean']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance\n",
    "Better SARIMA. So we will use SARIMA for the compute of the score based on arrival. Let's motivate the process:\n",
    "- Mean Average Error (MSE): Tells us the average magnitude of the forecast errors. \n",
    "- Mean Square Error: Emphasizes larger errors more than MAE. \n",
    "- Root Mean Square Error: Provides an error measure in the same units as the demand. \n",
    "\n",
    "## Comparing Models\n",
    "- SARIMA shows an higher MAE than Prophet but perform better since MSE and RMSE are lower.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute evaluation metrics\n",
    "# For Prophet\n",
    "prophet_true = weekly_demand['Demand'].values[-52:]\n",
    "prophet_pred = forecast_prophet['yhat'].values[:52]\n",
    "prophet_mae = mean_absolute_error(prophet_true, prophet_pred)\n",
    "prophet_mse = mean_squared_error(prophet_true, prophet_pred)\n",
    "prophet_rmse = np.sqrt(prophet_mse)\n",
    "\n",
    "# For ARIMA\n",
    "arima_true = weekly_demand['Demand'].values[-52:]\n",
    "arima_pred = forecast_arima_df['mean'].values[:52]\n",
    "arima_mae = mean_absolute_error(arima_true, arima_pred)\n",
    "arima_mse = mean_squared_error(arima_true, arima_pred)\n",
    "arima_rmse = np.sqrt(arima_mse)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Prophet MAE: {prophet_mae}, MSE: {prophet_mse}, RMSE: {prophet_rmse}\")\n",
    "print(f\"ARIMA MAE: {arima_mae}, MSE: {arima_mse}, RMSE: {arima_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Review Score</b> using BERT Sentiment Analysis over Tripadvisor Reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Hotel performance in terms of revenue depends stricly from online reputation (cit), so our goal in designing <b>HotelRank</p> algorithm is to analyze reviews about our customers hotel and provide an unique score to put a linear factor in HotelRank. We can name that score as <i>review score</i>.</p>\n",
    "<p><B>ReviewScore = Hotel_Rating - (0.5 * #number_negative review) + (0.25 * number of positive review)</B></p>\n",
    "<p>Here we emphasize the idea that is better not having negitive than positive reviews. To compute this formula we need we are in need to perform sentiment analysis over hotel reviews.</p><p>In case the <b>ReviewScore</b> is negative we assume that his weight to HotelRank is 0</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state-of-the-art sentiment analysis can be accomplished by fine-tuning pretrained BERT models with sentiment-analysis datasets. Fine-tuning is accomplished by further training a pretrained model for a limited number of epochs and with a reduced learning rate. We have collected the review using a scraper that we've coded in Go programming Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(samples):\n",
    "    return tokenizer(samples['Text'], truncation=True)\n",
    "\n",
    "tokenized_imdb = imdb.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the reviews are tokenized, they need to be converted from [Hugging Face datasets](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset) into [TensorFlow datasets](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) with Hugging Face’s [Dataset.to_tf_dataset](https://huggingface.co/docs/datasets/package_reference/main_classes#datasets.Dataset.to_tf_dataset) method. The collating function passed to that method dynamically pads the sequences so they’re all the same length. You can also ask the tokenizer to do the padding, but padding performed that way is static and requires more memory:\n",
    "                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors='tf')\n",
    "\n",
    "train_data = tokenized_imdb['train'].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'label'],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "validation_data = tokenized_imdb['test'].to_tf_dataset(\n",
    "    columns=['attention_mask', 'input_ids', 'label'],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you’re ready to fine-tune. Call `fit` on the model as usual, but set the `Adam` optimizer’s learning rate (the nominal amount that weights and biases are adjusted during backpropagation passes) to 0.00002, which is a fraction of the default learning rate of 0.001:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "model.compile(Adam(learning_rate=2e-5), metrics=['accuracy'])\n",
    "hist = model.fit(train_data, validation_data=validation_data, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "acc = hist.history['accuracy']\n",
    "val = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish up by defining an `analyze_text` function that returns a sentiment score and using it to score a positive review for sentiment. The model returns an object wrapping a tensor containing unnormalized sentiment scores (negative and positive), but you can use TensorFlow’s `softmax` function to normalize them to values from 0.0 to 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import panda as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "def analyze_text(text, tokenizer, model):\n",
    "    tokenized_text = tokenizer(text, padding=True, truncation=True, return_tensors='tf')\n",
    "    prediction = model(tokenized_text)\n",
    "    return tf.nn.softmax(prediction[0]).numpy()[0][1]\n",
    "\n",
    "review_data = glob.glob('review_data/*.csv')\n",
    "datasets = [pd.read_csv(filedata) for filedata in review_data]\n",
    "datasets[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancellation Score: Analysis on Cancellations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
